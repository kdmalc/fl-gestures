{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b04f99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f961eccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do these need to get imported still if they're imported in the other .py file? Idk\n",
    "#from sklearn.decomposition import PCA\n",
    "#from sklearn.manifold import TSNE\n",
    "#from sklearn.decomposition import IncrementalPCA\n",
    "#from sklearn.decomposition import KernelPCA\n",
    "#from umap import UMAP\n",
    "#from sklearn.manifold import MDS\n",
    "#from sklearn.manifold import Isomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d49703",
   "metadata": {},
   "outputs": [],
   "source": [
    "from subspace_clustering_helper_funcs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5a9b09",
   "metadata": {},
   "source": [
    "- https://scikit-learn.org/stable/modules/classes.html#module-sklearn.manifold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e073f3",
   "metadata": {},
   "source": [
    "## Loading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904a58ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove pID 101 because it doesn't exist\n",
    "#remove pID 131 because it  doesnt have enough user defined gestures\n",
    "# each participant has 100 experimenter defined files and 50 user defined files\n",
    "#10 experimenter defined gestures and 5 user defined gestures\n",
    "\n",
    "file_types = [\"IMU_extract\", \"movavg_files\"]\n",
    "expt_types = [\"experimenter-defined\"]\n",
    "\n",
    "#remove participant 131 because they are missing gestures \n",
    "pIDs_impaired = ['P102','P103','P104','P105','P106','P107','P108','P109','P110','P111',\n",
    "       'P112','P114','P115','P116','P118','P119','P121','P122','P123','P124','P125',\n",
    "       'P126','P127','P128', 'P132']\n",
    "# remove participants P001 and P003 because they dont have duplicate or open gestures\n",
    "pIDs_unimpaired = ['P004','P005','P006','P008','P010','P011']\n",
    "\n",
    "pIDs_both = pIDs_impaired + pIDs_unimpaired"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9683588f",
   "metadata": {},
   "source": [
    "From Ben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38279fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(pIDs, plot_raw, plot_interpolated, data_dir_path=\"C:\\\\Users\\\\kdmen\\\\Box Sync\\\\$M data segmented\\\\segmented_filtered_data\\\\\"):    \n",
    "    \"\"\"\n",
    "    generate data set for experimenter defined gestures\n",
    "    the data structure will be a nested dictionary with multiple tiers:\n",
    "    first level will be the participant id\n",
    "    second level will be the file type: IMU or EMG\n",
    "    third level will be the gestureID\n",
    "    the third level will contain all 10 trials for each gesture smashed together vertically\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Loading Data\")\n",
    "    global_path = data_dir_path\n",
    "    data ={}\n",
    "    for expt_type in expt_types:\n",
    "        for pid in pIDs:\n",
    "            print(pid)\n",
    "            data[pid] = {}\n",
    "            path = global_path + pid + \"\\\\\"\n",
    "            for file_type in file_types:\n",
    "                data[pid][file_type] = {}\n",
    "                sub_path = path + file_type #+ \"\\\\\"\n",
    "                for file in os.listdir(sub_path):\n",
    "                        split_filename = file.split(\"_\")\n",
    "                        gestureID = split_filename[4]\n",
    "                        gestureNum = split_filename[5]\n",
    "                        if file_type == \"movavg_files\":\n",
    "                            headers=['EMG1','EMG2','EMG3','EMG4','EMG5',\n",
    "                                                           'EMG6','EMG7','EMG8','EMG9','EMG10',\n",
    "                                                           'EMG11','EMG12','EMG13','EMG14','EMG15',\n",
    "                                                           'EMG16']\n",
    "                        else:\n",
    "                            headers= ['IMU1_ax', 'IMU1_ay', 'IMU1_az', 'IMU1_vx', 'IMU1_vy', 'IMU1_vz',\n",
    "                                    'IMU2_ax', 'IMU2_ay', 'IMU2_az', 'IMU2_vx', 'IMU2_vy', 'IMU2_vz', \n",
    "                                    'IMU3_ax', 'IMU3_ay', 'IMU3_az', 'IMU3_vx', 'IMU3_vy', 'IMU3_vz',\n",
    "                                    'IMU4_ax', 'IMU4_ay', 'IMU4_az', 'IMU4_vx', 'IMU4_vy', 'IMU4_vz', \n",
    "                                    'IMU5_ax', 'IMU5_ay', 'IMU5_az', 'IMU5_vx', 'IMU5_vy', 'IMU5_vz',\n",
    "                                    'IMU6_ax', 'IMU6_ay', 'IMU6_az', 'IMU6_vx', 'IMU6_vy', 'IMU6_vz',\n",
    "                                    'IMU7_ax', 'IMU7_ay', 'IMU7_az', 'IMU7_vx', 'IMU7_vy', 'IMU7_vz', \n",
    "                                    'IMU8_ax', 'IMU8_ay', 'IMU8_az', 'IMU8_vx', 'IMU8_vy', 'IMU8_vz', \n",
    "                                    'IMU9_ax', 'IMU9_ay', 'IMU9_az', 'IMU9_vx', 'IMU9_vy', 'IMU9_vz', \n",
    "                                    'IMU11_ax', 'IMU11_ay', 'IMU11_az', 'IMU11_vx', 'IMU11_vy', 'IMU11_vz', \n",
    "                                    'IMU13_ax', 'IMU13_ay', 'IMU13_az', 'IMU13_vx', 'IMU13_vy', 'IMU13_vz', \n",
    "                                    'IMU15_ax', 'IMU15_ay', 'IMU15_az', 'IMU15_vx', 'IMU15_vy', 'IMU15_vz']\n",
    "                        #read the data \n",
    "                        df = pd.read_csv(sub_path + \"\\\\\" + file,names=headers,header=0)\n",
    "                        \n",
    "                        #interpolate the data \n",
    "                        df_interpolated = interpolate_dataframe(df, num_rows=64)\n",
    "\n",
    "                        if gestureID not in data[pid][file_type]:\n",
    "                            #create the dataframe for the emgs of this gesture for this user\n",
    "                            data[pid][file_type][gestureID] = df_interpolated\n",
    "                        else:\n",
    "                            #smash them together \n",
    "                            data[pid][file_type][gestureID]= pd.concat([data[pid][file_type][gestureID], df_interpolated])\n",
    "    print(\"Loading Complete\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec151ceb",
   "metadata": {},
   "source": [
    "Data from Box Sync still isn't loaded in yet..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009866bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(pIDs_both, False, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cfda36",
   "metadata": {},
   "source": [
    "Rewritten version using dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c8a1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_types = [\"IMU_extract\", \"movavg_files\"]\n",
    "expt_types = [\"experimenter-defined\"]\n",
    "\n",
    "def load_data(pIDs, data_dir_path=\"C:\\\\Users\\\\kdmen\\\\Box Sync\\\\$M data segmented\\\\segmented_filtered_data\\\\\"):\n",
    "    \n",
    "    data_list = []\n",
    "    \n",
    "    for pid in pIDs:\n",
    "        path = os.path.join(data_dir_path, pid)\n",
    "        for expt_type in expt_types:\n",
    "            for file_type in file_types:\n",
    "                sub_path = os.path.join(path, file_type)\n",
    "                for file in os.listdir(sub_path):\n",
    "                    split_filename = file.split(\"_\")\n",
    "                    gestureID = split_filename[4]\n",
    "                    gestureNum = split_filename[5]\n",
    "                    gesture_type = expt_type\n",
    "                    \n",
    "                    if file_type == \"movavg_files\":\n",
    "                        headers = ['EMG1','EMG2','EMG3','EMG4','EMG5',\n",
    "                                   'EMG6','EMG7','EMG8','EMG9','EMG10',\n",
    "                                   'EMG11','EMG12','EMG13','EMG14','EMG15',\n",
    "                                   'EMG16']\n",
    "                    else:\n",
    "                        headers = ['IMU1_ax', 'IMU1_ay', 'IMU1_az', 'IMU1_vx', 'IMU1_vy', 'IMU1_vz',\n",
    "                                   'IMU2_ax', 'IMU2_ay', 'IMU2_az', 'IMU2_vx', 'IMU2_vy', 'IMU2_vz', \n",
    "                                   'IMU3_ax', 'IMU3_ay', 'IMU3_az', 'IMU3_vx', 'IMU3_vy', 'IMU3_vz',\n",
    "                                   'IMU4_ax', 'IMU4_ay', 'IMU4_az', 'IMU4_vx', 'IMU4_vy', 'IMU4_vz', \n",
    "                                   'IMU5_ax', 'IMU5_ay', 'IMU5_az', 'IMU5_vx', 'IMU5_vy', 'IMU5_vz',\n",
    "                                   'IMU6_ax', 'IMU6_ay', 'IMU6_az', 'IMU6_vx', 'IMU6_vy', 'IMU6_vz',\n",
    "                                   'IMU7_ax', 'IMU7_ay', 'IMU7_az', 'IMU7_vx', 'IMU7_vy', 'IMU7_vz', \n",
    "                                   'IMU8_ax', 'IMU8_ay', 'IMU8_az', 'IMU8_vx', 'IMU8_vy', 'IMU8_vz', \n",
    "                                   'IMU9_ax', 'IMU9_ay', 'IMU9_az', 'IMU9_vx', 'IMU9_vy', 'IMU9_vz', \n",
    "                                   'IMU11_ax', 'IMU11_ay', 'IMU11_az', 'IMU11_vx', 'IMU11_vy', 'IMU11_vz', \n",
    "                                   'IMU13_ax', 'IMU13_ay', 'IMU13_az', 'IMU13_vx', 'IMU13_vy', 'IMU13_vz', \n",
    "                                   'IMU15_ax', 'IMU15_ay', 'IMU15_az', 'IMU15_vx', 'IMU15_vy', 'IMU15_vz']\n",
    "                    df = pd.read_csv(os.path.join(sub_path, file), names=headers, header=0)\n",
    "                    df['Participant'] = pid\n",
    "                    df['Gesture_ID'] = gestureID\n",
    "                    df['Gesture_Num'] = gestureNum\n",
    "                    df['Gesture_Type'] = gesture_type\n",
    "                    data_list.append(df)\n",
    "    \n",
    "    # Concatenate all dataframes into one\n",
    "    dataframe = pd.concat(data_list, ignore_index=True)\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c64b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = load_data(pIDs_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d57165",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_df.shape)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab80b591",
   "metadata": {},
   "source": [
    "## Applying dimensionality reduction algorithms:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dee529",
   "metadata": {},
   "source": [
    "Modified version of Ben's PCA_all_participants() func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945766be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_dim_reduc(model_str, data_df, num_dims, hp=None, modality=['EMG and IMU'], participant_inclusion=['All Participants']):\n",
    "    '''\n",
    "    model_str: what kind of model to use (eg PCA, T-SNE, ...)\n",
    "    data_df: df containing all the (training) data\n",
    "    num_dims: how many dimensions/components should be used [HYPERPARAM!]\n",
    "    hp: [hyperparams] use this to store \n",
    "    modality: ['EMG', 'IMU', 'EMG and IMU']\n",
    "    '''\n",
    "    \n",
    "    gestures = ['pan', 'duplicate', 'zoom-out', 'zoom-in', 'move', 'rotate', 'select-single', 'delete', 'close', 'open']\n",
    "    data_types = modality\n",
    "    participant_types = participant_inclusion\n",
    "        \n",
    "    for f_type in data_types:\n",
    "        # Why does this exist if we already extracted the data...\n",
    "        if f_type == 'EMG':\n",
    "            file_types = ['movavg_files']\n",
    "        if f_type == 'IMU':\n",
    "            file_types = ['IMU_extract']\n",
    "        if f_type == 'EMG and IMU':\n",
    "            file_types = ['movavg_files', 'IMU_extract']\n",
    "            \n",
    "        for p_type in participant_types:\n",
    "            \n",
    "            if p_type == \"All Participants\":\n",
    "                pIDs = data_df['Participant'].unique()\n",
    "            elif p_type == \"Impaired Participants\":\n",
    "                pIDs = data_df[data_df['Participant'].isin(pIDs_impaired)]['Participant'].unique()\n",
    "            elif p_type == \"Unimpaired Participants\":\n",
    "                pIDs = data_df[data_df['Participant'].isin(pIDs_unimpaired)]['Participant'].unique()\n",
    "            else:\n",
    "                raise ValueError(f\"Participant type {p_type} not supported, check supported versions.\")\n",
    "               \n",
    "            if apply_all:\n",
    "                # Figure out where/how it determines whether it is applying it to all data or not..\n",
    "                ## Pass in just EMG data, or pass in full thing and cut it up after\n",
    "                ### If the latter, do I need to cut it up for every single case...\n",
    "                for file_type in file_types:\n",
    "                    # Simplify this down to just using 1 of these fields, depending on what data_df looks like...\n",
    "                    df = data_df[(data_df['Gesture_Type'] == f_type) & \n",
    "                                 (data_df['File_Type'] == file_type)]\n",
    "\n",
    "                    df_t = apply_model(model_str, df, num_dims, hp)\n",
    "            elif apply_by_user:\n",
    "                for pid in pIDs:\n",
    "                    for file_type in file_types:\n",
    "                            df = data_df[(data_df['Participant'] == pid) & \n",
    "                                         (data_df['Gesture_Type'] == f_type) & \n",
    "                                         (data_df['File_Type'] == file_type)]\n",
    "\n",
    "                            df_t = apply_model(model_str, df, num_dims, hp)\n",
    "            elif apply_by_gesture:\n",
    "                for file_type in file_types:\n",
    "                    for gesture in gestures:\n",
    "                        df = data_df[(data_df['Gesture_ID'] == gesture) & \n",
    "                                     (data_df['Gesture_Type'] == f_type) & \n",
    "                                     (data_df['File_Type'] == file_type)]\n",
    "                        \n",
    "                        df_t = apply_model(model_str, df, num_dims, hp)\n",
    "\n",
    "            return df_t\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1625f5de",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3b26ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_dim_reduc():\n",
    "    # AIC? ...\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff4411a",
   "metadata": {},
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f607692e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to do train/test splits?\n",
    "# I have plenty of clustering metrics but not dim reduc specific ones..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5043a83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da15f47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
