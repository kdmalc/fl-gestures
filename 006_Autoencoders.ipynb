{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1ef1e63-343c-4d55-ad97-cf3cabb3fc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347da32c-36cc-49e0-80cd-e5b456561a30",
   "metadata": {},
   "source": [
    "# Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "533b39ce-387c-4e40-b5bd-58dd97d233f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove pID 101 because it doesn't exist\n",
    "# remove pID 131 because it  doesnt have enough user defined gestures\n",
    "# each participant has 100 experimenter defined files and 50 user defined files\n",
    "# 10 experimenter defined gestures and 5 user defined gestures\n",
    "\n",
    "file_types = [\"IMU_extract\", \"movavg_files\"]\n",
    "expt_types = [\"experimenter-defined\"]\n",
    "\n",
    "#remove participant 131 because they are missing gestures \n",
    "pIDs_impaired = ['P102','P103','P104','P105','P106','P107','P108','P109','P110','P111',\n",
    "       'P112','P114','P115','P116','P118','P119','P121','P122','P123','P124','P125',\n",
    "       'P126','P127','P128', 'P132']\n",
    "# remove participants P001 and P003 because they dont have duplicate or open gestures\n",
    "pIDs_unimpaired = ['P004','P005','P006','P008','P010','P011']\n",
    "\n",
    "pIDs_both = pIDs_impaired + pIDs_unimpaired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "647a91a5-4d27-485f-8ed0-db92218ccb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading\n"
     ]
    }
   ],
   "source": [
    "# Kai's laptop\n",
    "data_path = \"C:\\\\Users\\\\kdmen\\\\Desktop\\\\Research\\\\Data\\\\$M\\\\PCA_40D\\\\\"\n",
    "# BRC Desktop\n",
    "#data_path = \"D:\\\\Kai_MetaGestureClustering_24\\\\saved_datasets\\\\\"\n",
    "\n",
    "print(\"Loading\")\n",
    "\n",
    "metadata_cols = ['Participant', 'Gesture_ID', 'Gesture_Num']\n",
    "\n",
    "PCA_df = pd.read_pickle(data_path+'PCA_ms_IMUEMG_df.pkl')\n",
    "metadata_cols_df = pd.read_pickle('C:\\\\Users\\\\kdmen\\\\Desktop\\\\Research\\\\Data\\\\$M\\\\metadata_cols_df.pkl')\n",
    "\n",
    "# Dropping the metadata when we read it in!\n",
    "training_u_df = pd.read_pickle(data_path+'training_u_df.pkl').drop(metadata_cols, axis=1)\n",
    "test_users_df = pd.read_pickle(data_path+'test_users_df.pkl').drop(metadata_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c0430ab-dd10-48ee-b823-b5a91d36b3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(327168, 40)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.027903</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>-0.019509</td>\n",
       "      <td>0.013428</td>\n",
       "      <td>-0.019699</td>\n",
       "      <td>0.027333</td>\n",
       "      <td>-0.031254</td>\n",
       "      <td>-0.022910</td>\n",
       "      <td>0.066484</td>\n",
       "      <td>0.108729</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019453</td>\n",
       "      <td>0.062983</td>\n",
       "      <td>-0.025869</td>\n",
       "      <td>0.014303</td>\n",
       "      <td>-0.013387</td>\n",
       "      <td>-0.037645</td>\n",
       "      <td>-0.186270</td>\n",
       "      <td>-0.046251</td>\n",
       "      <td>-0.104630</td>\n",
       "      <td>-0.002939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.038982</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>-0.000111</td>\n",
       "      <td>0.010904</td>\n",
       "      <td>-0.015323</td>\n",
       "      <td>0.031336</td>\n",
       "      <td>-0.007901</td>\n",
       "      <td>-0.027368</td>\n",
       "      <td>0.060370</td>\n",
       "      <td>0.074712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041438</td>\n",
       "      <td>0.035053</td>\n",
       "      <td>-0.056843</td>\n",
       "      <td>-0.008895</td>\n",
       "      <td>-0.022542</td>\n",
       "      <td>-0.022563</td>\n",
       "      <td>-0.160826</td>\n",
       "      <td>-0.048161</td>\n",
       "      <td>-0.073771</td>\n",
       "      <td>0.043268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.116782</td>\n",
       "      <td>0.003824</td>\n",
       "      <td>0.011550</td>\n",
       "      <td>-0.014612</td>\n",
       "      <td>-0.093325</td>\n",
       "      <td>0.081718</td>\n",
       "      <td>-0.013155</td>\n",
       "      <td>-0.046150</td>\n",
       "      <td>0.036385</td>\n",
       "      <td>0.052746</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014298</td>\n",
       "      <td>0.072109</td>\n",
       "      <td>-0.026536</td>\n",
       "      <td>-0.034365</td>\n",
       "      <td>0.018695</td>\n",
       "      <td>-0.011940</td>\n",
       "      <td>-0.160580</td>\n",
       "      <td>-0.041831</td>\n",
       "      <td>-0.109653</td>\n",
       "      <td>0.027043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.030245</td>\n",
       "      <td>-0.017409</td>\n",
       "      <td>0.022540</td>\n",
       "      <td>-0.048905</td>\n",
       "      <td>-0.029129</td>\n",
       "      <td>0.090026</td>\n",
       "      <td>-0.024645</td>\n",
       "      <td>-0.064307</td>\n",
       "      <td>0.074589</td>\n",
       "      <td>0.053055</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010992</td>\n",
       "      <td>0.059990</td>\n",
       "      <td>-0.097073</td>\n",
       "      <td>-0.056870</td>\n",
       "      <td>-0.001038</td>\n",
       "      <td>-0.008015</td>\n",
       "      <td>-0.165858</td>\n",
       "      <td>-0.049424</td>\n",
       "      <td>-0.108671</td>\n",
       "      <td>0.069886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.112950</td>\n",
       "      <td>0.026262</td>\n",
       "      <td>0.004837</td>\n",
       "      <td>-0.063254</td>\n",
       "      <td>-0.108892</td>\n",
       "      <td>0.198729</td>\n",
       "      <td>-0.010583</td>\n",
       "      <td>-0.124893</td>\n",
       "      <td>0.114817</td>\n",
       "      <td>0.038628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035735</td>\n",
       "      <td>0.050880</td>\n",
       "      <td>-0.093678</td>\n",
       "      <td>-0.131263</td>\n",
       "      <td>0.018035</td>\n",
       "      <td>0.056185</td>\n",
       "      <td>-0.157963</td>\n",
       "      <td>-0.041911</td>\n",
       "      <td>-0.145308</td>\n",
       "      <td>0.063311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6    \n",
       "0 -0.027903  0.001411 -0.019509  0.013428 -0.019699  0.027333 -0.031254  \\\n",
       "1 -0.038982  0.006470 -0.000111  0.010904 -0.015323  0.031336 -0.007901   \n",
       "2 -0.116782  0.003824  0.011550 -0.014612 -0.093325  0.081718 -0.013155   \n",
       "3 -0.030245 -0.017409  0.022540 -0.048905 -0.029129  0.090026 -0.024645   \n",
       "4 -0.112950  0.026262  0.004837 -0.063254 -0.108892  0.198729 -0.010583   \n",
       "\n",
       "         7         8         9   ...        30        31        32        33   \n",
       "0 -0.022910  0.066484  0.108729  ... -0.019453  0.062983 -0.025869  0.014303  \\\n",
       "1 -0.027368  0.060370  0.074712  ...  0.041438  0.035053 -0.056843 -0.008895   \n",
       "2 -0.046150  0.036385  0.052746  ... -0.014298  0.072109 -0.026536 -0.034365   \n",
       "3 -0.064307  0.074589  0.053055  ... -0.010992  0.059990 -0.097073 -0.056870   \n",
       "4 -0.124893  0.114817  0.038628  ...  0.035735  0.050880 -0.093678 -0.131263   \n",
       "\n",
       "         34        35        36        37        38        39  \n",
       "0 -0.013387 -0.037645 -0.186270 -0.046251 -0.104630 -0.002939  \n",
       "1 -0.022542 -0.022563 -0.160826 -0.048161 -0.073771  0.043268  \n",
       "2  0.018695 -0.011940 -0.160580 -0.041831 -0.109653  0.027043  \n",
       "3 -0.001038 -0.008015 -0.165858 -0.049424 -0.108671  0.069886  \n",
       "4  0.018035  0.056185 -0.157963 -0.041911 -0.145308  0.063311  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(training_u_df.shape)\n",
    "training_u_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cab3ccc-82b7-4db1-8ee8-706461cc31be",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows_per_gesture = 64 # From the interp\n",
    "num_gestures = len(training_u_df) // num_rows_per_gesture\n",
    "num_features = training_u_df.shape[1]\n",
    "\n",
    "# Ensure the data can be evenly divided into gestures\n",
    "assert len(training_u_df) % num_rows_per_gesture == 0, \"The total number of rows is not a multiple of the number of rows per gesture.\"\n",
    "\n",
    "# Convert DataFrame to NumPy array\n",
    "data_np = training_u_df.to_numpy()\n",
    "# Reshape into (batch_dim, time_step, n_features) AKA (n_gestures, n_rows_per_gesture, n_columns)\n",
    "X_3D_PCA40 = data_np.reshape(num_gestures, num_rows_per_gesture, num_features)\n",
    "#flattened_PCA = PCA_np.reshape(num_gestures, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6640d67d-fe1b-43e3-8afe-9af1a0035867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensor\n",
    "X_3DTensor_PCA40 = torch.tensor(X_3D_PCA40, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3eaec717-afd4-4292-8e6b-eaec1c3b0e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GestureDataset(Dataset):\n",
    "    def __init__(self, data_tensor):\n",
    "        self.data = data_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1627b00-98d0-4f47-927e-5c711c78240d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64, 40])\n",
      "\n",
      "NEW BATCH SHAPE! INCONSISTENT BATCH SIZES! At batch_counter 160\n",
      "torch.Size([24, 64, 40])\n",
      "\n",
      "Completed. Final batch_counter: 160\n"
     ]
    }
   ],
   "source": [
    "# Create the dataset\n",
    "u_training_dataset = GestureDataset(X_3DTensor_PCA40)\n",
    "\n",
    "batch_size = 32  # Adjust batch size as needed\n",
    "data_loader = DataLoader(u_training_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Example of iterating through the DataLoader\n",
    "batch_counter = 0\n",
    "consistent_batch_shape = 0\n",
    "for batch in data_loader:\n",
    "    batch_counter += 1\n",
    "    if batch_counter == 1:\n",
    "        # Should print (batch_size, 64, 40)\n",
    "        print(batch.shape)\n",
    "        print()\n",
    "        consistent_batch_shape = batch.shape\n",
    "    elif batch.shape != consistent_batch_shape:\n",
    "        print(f\"NEW BATCH SHAPE! INCONSISTENT BATCH SIZES! At batch_counter {batch_counter}\")\n",
    "        print(batch.shape)\n",
    "        print()\n",
    "        \n",
    "print(f\"Completed. Final batch_counter: {batch_counter}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace9b852-4054-443f-a4e9-bdb280c5cc84",
   "metadata": {},
   "source": [
    "# RNN Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9457e642-d94d-43a7-9771-5d578dd18bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers):\n",
    "        super(RNNEncoder, self).__init__()\n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        _, (hidden, _) = self.rnn(x)\n",
    "        return hidden[-1]\n",
    "\n",
    "class RNNDecoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim, num_layers):\n",
    "        super(RNNDecoder, self).__init__()\n",
    "        self.rnn = nn.LSTM(hidden_dim, output_dim, num_layers, batch_first=True)\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "    def forward(self, x, seq_len):\n",
    "        x = x.unsqueeze(1).repeat(1, seq_len, 1)\n",
    "        x, _ = self.rnn(x)\n",
    "        return x\n",
    "\n",
    "class RNNAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers):\n",
    "        super(RNNAutoencoder, self).__init__()\n",
    "        self.encoder = RNNEncoder(input_dim, hidden_dim, num_layers)\n",
    "        self.decoder = RNNDecoder(hidden_dim, input_dim, num_layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(1)\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded, seq_len)\n",
    "        return decoded\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b04eea-0d32-46d2-8a7e-9ea6ad8fb220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_dim = data.size(2)\n",
    "hidden_dim = 128\n",
    "num_layers = 2\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Model, Loss, and Optimizer\n",
    "model = RNNAutoencoder(input_dim, hidden_dim, num_layers)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330b20a2-eb0a-492c-883f-e2603f295521",
   "metadata": {},
   "source": [
    "# Temporal Convolution Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85022701-bada-40a8-99d2-21938d17978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCNEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size):\n",
    "        super(TCNEncoder, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_dim, hidden_dim, kernel_size, padding=kernel_size//2)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "class TCNDecoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim, kernel_size):\n",
    "        super(TCNDecoder, self).__init__()\n",
    "        self.conv1 = nn.ConvTranspose1d(hidden_dim, output_dim, kernel_size, padding=kernel_size//2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return x\n",
    "\n",
    "class TCNAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size):\n",
    "        super(TCNAutoencoder, self).__init__()\n",
    "        self.encoder = TCNEncoder(input_dim, hidden_dim, kernel_size)\n",
    "        self.decoder = TCNDecoder(hidden_dim, input_dim, kernel_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09094d09-9f33-4f45-b28e-31795d511dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hidden_dim = 64\n",
    "kernel_size = 5\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Model, Loss, and Optimizer\n",
    "model = TCNAutoencoder(input_dim, hidden_dim, kernel_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc824e7-03e0-4eae-b880-6be6118a56fb",
   "metadata": {},
   "source": [
    "# Varitational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b356ebb-4b72-46d1-a1a0-8fd21c163c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, latent_dim*2)  # mean and logvar\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        h = self.encoder(x)\n",
    "        mu, logvar = h.chunk(2, dim=-1)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decoder(z), mu, logvar\n",
    "\n",
    "    def loss_function(self, recon_x, x, mu, logvar):\n",
    "        BCE = nn.functional.binary_cross_entropy(recon_x, x.view(-1, input_dim), reduction='sum')\n",
    "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        return BCE + KLD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5138cb2d-7d58-4f83-8dcd-0074f0544c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_dim = data.size(1) * data.size(2)\n",
    "hidden_dim = 128\n",
    "latent_dim = 32\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Model, Loss, and Optimizer\n",
    "model = VAE(input_dim, hidden_dim, latent_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(batch)\n",
    "        loss = model.loss_function(recon_batch, batch, mu, logvar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68375495-db2c-4b19-83af-8d69eaa5b701",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
