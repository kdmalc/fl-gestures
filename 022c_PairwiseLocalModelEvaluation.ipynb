{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a499671-e6c5-4f0a-b6f4-cfe645725d72",
   "metadata": {},
   "source": [
    "> __Purpose:__ The goal of this NB is to train single user local models, and show performance of each user's model tested on every other user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "615b90b2-ae93-4cf1-8365-433ced7e111a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#import torch.nn as nn\n",
    "#import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from utils.ae_torch_classes import *\n",
    "#from utils.LSTM_gesture_classifier import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87cbe772-e960-4cc0-b5b3-945884c32482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# C:\\Users\\kdmen\\miniconda3\\envs\\fl_torch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning warnings.warn("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "368a736f-a5a5-46c4-b8f0-8bd55f3a62b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_loading_paths import *\n",
    "\n",
    "kai_laptop = True\n",
    "brc_desktop = False\n",
    "\n",
    "if kai_laptop:\n",
    "    data_path = kai_data_path\n",
    "    model_dir_path = kai_model_dir_path\n",
    "    metadata_path = kai_metadata_path\n",
    "elif brc_desktop:\n",
    "    data_path = brc_data_path\n",
    "    model_dir_path = brc_model_dir_path\n",
    "    metadata_path = brc_metadata_path\n",
    "\n",
    "metadata_cols_df = pd.read_pickle(metadata_path)\n",
    "\n",
    "emg_training_users_df = pd.read_pickle(data_path+emg_dir+'training_users_df.pkl').drop(metadata_cols, axis=1)\n",
    "emg_test_users_df = pd.read_pickle(data_path+emg_dir+'test_users_df.pkl').drop(metadata_cols, axis=1)\n",
    "\n",
    "both_training_users_df = pd.read_pickle(data_path+both_dir+'training_users_df.pkl').drop(metadata_cols, axis=1)\n",
    "both_test_users_df = pd.read_pickle(data_path+both_dir+'test_users_df.pkl').drop(metadata_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb4c8509-e9cb-415d-9f84-506eb7d8b8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(204800, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant</th>\n",
       "      <th>Gesture_ID</th>\n",
       "      <th>Gesture_Num</th>\n",
       "      <th>EMG1</th>\n",
       "      <th>EMG2</th>\n",
       "      <th>EMG3</th>\n",
       "      <th>EMG4</th>\n",
       "      <th>EMG5</th>\n",
       "      <th>EMG6</th>\n",
       "      <th>EMG7</th>\n",
       "      <th>EMG8</th>\n",
       "      <th>EMG9</th>\n",
       "      <th>EMG10</th>\n",
       "      <th>EMG11</th>\n",
       "      <th>EMG12</th>\n",
       "      <th>EMG13</th>\n",
       "      <th>EMG14</th>\n",
       "      <th>EMG15</th>\n",
       "      <th>EMG16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P102</td>\n",
       "      <td>pan</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.362743</td>\n",
       "      <td>-0.801651</td>\n",
       "      <td>-0.383077</td>\n",
       "      <td>-0.195299</td>\n",
       "      <td>-0.203047</td>\n",
       "      <td>-0.464472</td>\n",
       "      <td>-0.276292</td>\n",
       "      <td>-0.026736</td>\n",
       "      <td>-0.873870</td>\n",
       "      <td>-1.036152</td>\n",
       "      <td>-0.580930</td>\n",
       "      <td>-0.719494</td>\n",
       "      <td>-0.502255</td>\n",
       "      <td>-1.750091</td>\n",
       "      <td>-0.127847</td>\n",
       "      <td>-0.094192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P102</td>\n",
       "      <td>pan</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.351553</td>\n",
       "      <td>-0.775334</td>\n",
       "      <td>-0.382545</td>\n",
       "      <td>-0.154773</td>\n",
       "      <td>-0.131977</td>\n",
       "      <td>-0.295204</td>\n",
       "      <td>-0.125822</td>\n",
       "      <td>0.089679</td>\n",
       "      <td>-0.816215</td>\n",
       "      <td>-2.082635</td>\n",
       "      <td>-0.006283</td>\n",
       "      <td>-0.139439</td>\n",
       "      <td>-0.367764</td>\n",
       "      <td>-0.208084</td>\n",
       "      <td>-0.111811</td>\n",
       "      <td>-0.039009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P102</td>\n",
       "      <td>pan</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.380825</td>\n",
       "      <td>-0.762588</td>\n",
       "      <td>-0.398388</td>\n",
       "      <td>-0.085411</td>\n",
       "      <td>0.017528</td>\n",
       "      <td>-0.205675</td>\n",
       "      <td>-0.068451</td>\n",
       "      <td>0.117076</td>\n",
       "      <td>-0.668221</td>\n",
       "      <td>-3.403064</td>\n",
       "      <td>-0.526030</td>\n",
       "      <td>-0.478294</td>\n",
       "      <td>-0.300443</td>\n",
       "      <td>0.203266</td>\n",
       "      <td>0.113300</td>\n",
       "      <td>0.004728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P102</td>\n",
       "      <td>pan</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.366795</td>\n",
       "      <td>-0.765464</td>\n",
       "      <td>-0.374423</td>\n",
       "      <td>-0.073225</td>\n",
       "      <td>0.183172</td>\n",
       "      <td>0.009277</td>\n",
       "      <td>-0.058907</td>\n",
       "      <td>0.080977</td>\n",
       "      <td>-0.424416</td>\n",
       "      <td>-3.709413</td>\n",
       "      <td>-0.570894</td>\n",
       "      <td>-0.775155</td>\n",
       "      <td>-0.144710</td>\n",
       "      <td>-0.619539</td>\n",
       "      <td>0.146499</td>\n",
       "      <td>0.199975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P102</td>\n",
       "      <td>pan</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.245578</td>\n",
       "      <td>-0.761283</td>\n",
       "      <td>-0.303976</td>\n",
       "      <td>-0.081947</td>\n",
       "      <td>0.224996</td>\n",
       "      <td>0.103319</td>\n",
       "      <td>-0.003929</td>\n",
       "      <td>0.041526</td>\n",
       "      <td>-0.016530</td>\n",
       "      <td>-4.075150</td>\n",
       "      <td>-0.127710</td>\n",
       "      <td>2.682791</td>\n",
       "      <td>-0.141750</td>\n",
       "      <td>-0.208404</td>\n",
       "      <td>-0.035642</td>\n",
       "      <td>0.172662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant Gesture_ID Gesture_Num      EMG1      EMG2      EMG3      EMG4   \n",
       "0        P102        pan           1 -0.362743 -0.801651 -0.383077 -0.195299  \\\n",
       "1        P102        pan           1 -0.351553 -0.775334 -0.382545 -0.154773   \n",
       "2        P102        pan           1 -0.380825 -0.762588 -0.398388 -0.085411   \n",
       "3        P102        pan           1 -0.366795 -0.765464 -0.374423 -0.073225   \n",
       "4        P102        pan           1 -0.245578 -0.761283 -0.303976 -0.081947   \n",
       "\n",
       "       EMG5      EMG6      EMG7      EMG8      EMG9     EMG10     EMG11   \n",
       "0 -0.203047 -0.464472 -0.276292 -0.026736 -0.873870 -1.036152 -0.580930  \\\n",
       "1 -0.131977 -0.295204 -0.125822  0.089679 -0.816215 -2.082635 -0.006283   \n",
       "2  0.017528 -0.205675 -0.068451  0.117076 -0.668221 -3.403064 -0.526030   \n",
       "3  0.183172  0.009277 -0.058907  0.080977 -0.424416 -3.709413 -0.570894   \n",
       "4  0.224996  0.103319 -0.003929  0.041526 -0.016530 -4.075150 -0.127710   \n",
       "\n",
       "      EMG12     EMG13     EMG14     EMG15     EMG16  \n",
       "0 -0.719494 -0.502255 -1.750091 -0.127847 -0.094192  \n",
       "1 -0.139439 -0.367764 -0.208084 -0.111811 -0.039009  \n",
       "2 -0.478294 -0.300443  0.203266  0.113300  0.004728  \n",
       "3 -0.775155 -0.144710 -0.619539  0.146499  0.199975  \n",
       "4  2.682791 -0.141750 -0.208404 -0.035642  0.172662  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_emg_df = pd.concat([metadata_cols_df, pd.concat([emg_training_users_df, emg_test_users_df])], axis=1)\n",
    "\n",
    "print(combined_emg_df.shape)\n",
    "combined_emg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4fefc8-0133-45f3-a6e4-f6b85fe06496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_dataset(dim_reduc_model_str, X, num_train_gestures, num_features, num_rows_per_gesture=64):\n",
    "    if dim_reduc_model_str == \"AE9\":\n",
    "        hidden_dim_lst = [9]\n",
    "        input_dim = 16\n",
    "        RNNAE_9mir_EMGFull = RNNAutoencoder(input_dim, hidden_dim_lst, num_layers=None, seq_len=num_rows_per_gesture, progressive=False, mirror=True)\n",
    "        RNNAE_9mir_EMGFull.load_state_dict(torch.load(model_dir_path+'RNNAE_9mir_vallossp277_EMGFull.pth'))\n",
    "    \n",
    "        X_3DTensor = torch.tensor(X.to_numpy().reshape(num_train_gestures, num_rows_per_gesture, num_features), dtype=torch.float32)\n",
    "        X_embedding = RNNAE_9mir_EMGFull.encode(X_3DTensor)\n",
    "        #print(f\"X_embedding.shape: {X_embedding.shape}\")\n",
    "        X = X_embedding.detach().numpy().reshape(num_train_gestures, -1)\n",
    "        #print(f\"New embedded X_train.shape: {X.shape}\")\n",
    "    elif dim_reduc_model_str == \"AE3\":\n",
    "        #hidden_dim_lst = ___\n",
    "        #input_dim = 16\n",
    "        #___ = RNNAutoencoder(input_dim, hidden_dim_lst, num_layers=None, seq_len=num_rows_per_gesture, progressive=False, mirror=True)\n",
    "        #___.load_state_dict(torch.load(model_dir_path+'___.pth'))\n",
    "        pass\n",
    "    elif dim_reduc_model_str == \"PCA?\":\n",
    "        pass\n",
    "    elif dim_reduc_model_str == \"PCA3\":\n",
    "        pass\n",
    "    elif dim_reduc_model_str is None:\n",
    "        X = X.reshape(num_train_gestures, -1)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "466218f3-4aeb-429a-823c-21c0eb1cf619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_model_permuatation_testing(df, dim_reduc_model_str, num_rows_per_gesture=64, batch_size=32, plot_heatmap=False, plot_clustermap=False, plot_title=None):\n",
    "\n",
    "    participants = df['Participant'].unique()\n",
    "    unique_gestures = df['Gesture_ID'].unique()\n",
    "    \n",
    "    num_train_gestures = len(df[df['Participant']=='P102']) // num_rows_per_gesture\n",
    "    num_emg_features = df.shape[-1] - 3\n",
    "    \n",
    "    # Initialize a DataFrame to store the accuracies\n",
    "    res_df = pd.DataFrame(index=participants, columns=participants, dtype=float)\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(unique_gestures)\n",
    "    \n",
    "    # Loop through each permutation of participants\n",
    "    for train_participant in participants:\n",
    "    \n",
    "        train_df = df[df['Participant'] == train_participant]\n",
    "        # Embed training data\n",
    "        X_train = embed_dataset(dim_reduc_model_str, train_df.iloc[:, 3:], num_train_gestures, num_emg_features)\n",
    "        # Encode training labels\n",
    "        y_train = label_encoder.transform(train_df['Gesture_ID'].iloc[::num_rows_per_gesture])\n",
    "    \n",
    "        knn = KNeighborsClassifier(n_neighbors=1)\n",
    "        knn.fit(X_train, y_train)\n",
    "        \n",
    "        for test_participant in participants:\n",
    "            if train_participant != test_participant:\n",
    "                test_df = df[df['Participant'] == test_participant]\n",
    "                # Embed testing data\n",
    "                X_test = embed_dataset(dim_reduc_model_str, test_df.iloc[:, 3:], num_train_gestures, num_emg_features)\n",
    "                # Encode testing labels\n",
    "                y_test = label_encoder.transform(test_df['Gesture_ID'].iloc[::num_rows_per_gesture])\n",
    "                \n",
    "                y_pred = knn.predict(X_test)\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                res_df.at[train_participant, test_participant] = accuracy\n",
    "\n",
    "    if plot_heatmap:\n",
    "        raise ValueError(\"Heatmap plotting is not yet supported\")\n",
    "    if plot_clustermap:\n",
    "        raise ValueError(\"Clustermap plotting is not yet supported\")\n",
    "\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0cf6ceb5-cf15-4850-95ff-9c088a203a6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m emg_ae9_res_df \u001b[38;5;241m=\u001b[39m \u001b[43mlocal_model_permuatation_testing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_emg_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAE9\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[50], line 29\u001b[0m, in \u001b[0;36mlocal_model_permuatation_testing\u001b[1;34m(df, dim_reduc_model_str, num_rows_per_gesture, batch_size, plot_heatmap, plot_clustermap, plot_title)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_participant \u001b[38;5;129;01min\u001b[39;00m participants:\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m train_participant \u001b[38;5;241m!=\u001b[39m test_participant:\n\u001b[1;32m---> 29\u001b[0m         test_df \u001b[38;5;241m=\u001b[39m df[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mParticipant\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_participant\u001b[49m]\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;66;03m# Embed testing data\u001b[39;00m\n\u001b[0;32m     31\u001b[0m         X_test \u001b[38;5;241m=\u001b[39m embed_dataset(dim_reduc_model_str, test_df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m3\u001b[39m:], num_train_gestures, num_emg_features)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\fl_torch\\lib\\site-packages\\pandas\\core\\ops\\common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     79\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\fl_torch\\lib\\site-packages\\pandas\\core\\arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\fl_torch\\lib\\site-packages\\pandas\\core\\series.py:6092\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6089\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   6091\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 6092\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6094\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\fl_torch\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:293\u001b[0m, in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_object_dtype(lvalues\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 293\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    296\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\fl_torch\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:83\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[1;34m(op, x, y)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     82\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mscalar_compare(x\u001b[38;5;241m.\u001b[39mravel(), y, op)\n\u001b[1;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "emg_ae9_res_df = local_model_permuatation_testing(combined_emg_df, 'AE9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf9f988-3345-44cc-82be-388ec4d02e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(emg_ae9_res_df, cmap='viridis', fmt=\".2f\", xticklabels=participants, yticklabels=participants) #, annot=True\n",
    "plt.xlabel('Participants')\n",
    "plt.ylabel('Participants')\n",
    "plt.title('Pairwise Model Accuracies')\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f941d848-3241-415c-9788-e2d6bf8230be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.clustermap(emg_ae9_res_df, metric='euclidean', cmap='viridis', annot=True, fmt=\".2f\", xticklabels=participants, yticklabels=participants)\n",
    "plt.xlabel('Participants')\n",
    "plt.ylabel('Participants')\n",
    "plt.title('Pairwise Model Accuracies')\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318f4bf4-283a-43eb-8384-616206685481",
   "metadata": {},
   "outputs": [],
   "source": [
    "emg_full_res_df = local_model_permuatation_testing(combined_emg_df, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a130c41-534f-45b4-b3a7-f59b318ee118",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(emg_full_res_df, cmap='viridis', fmt=\".2f\", xticklabels=participants, yticklabels=participants) #, annot=True\n",
    "plt.xlabel('Participants')\n",
    "plt.ylabel('Participants')\n",
    "plt.title('Pairwise Model Accuracies')\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b4c3b3-5f28-4b90-bea2-a5e3ba732fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.clustermap(emg_full_res_df, metric='euclidean', cmap='viridis', annot=True, fmt=\".2f\", xticklabels=participants, yticklabels=participants)\n",
    "plt.xlabel('Participants')\n",
    "plt.ylabel('Participants')\n",
    "plt.title('Pairwise Model Accuracies')\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef57cdc-8954-480e-add1-6da27d3bf684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cca68c2-b23a-4a65-86f0-adba44146a11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
