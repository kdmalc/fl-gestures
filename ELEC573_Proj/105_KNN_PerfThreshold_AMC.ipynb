{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c0fef36",
   "metadata": {},
   "source": [
    "> __Purpose:__ This NB tests KNN in the agglomerative model clustering procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b913190",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_str = \"KNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a62336d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "from moments_engr import *\n",
    "from agglo_model_clust import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33b80c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = 'C:\\\\Users\\\\kdmen\\\\Box\\\\Meta_Gesture_2024\\\\saved_datasets\\\\filtered_datasets\\\\$BStand_EMG_df.pkl'\n",
    "\n",
    "with open(path1, 'rb') as file:\n",
    "    raw_userdef_data_df = pickle.load(file)  # (204800, 19)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b710811a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(204800, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant</th>\n",
       "      <th>Gesture_ID</th>\n",
       "      <th>Gesture_Num</th>\n",
       "      <th>EMG1</th>\n",
       "      <th>EMG2</th>\n",
       "      <th>EMG3</th>\n",
       "      <th>EMG4</th>\n",
       "      <th>EMG5</th>\n",
       "      <th>EMG6</th>\n",
       "      <th>EMG7</th>\n",
       "      <th>EMG8</th>\n",
       "      <th>EMG9</th>\n",
       "      <th>EMG10</th>\n",
       "      <th>EMG11</th>\n",
       "      <th>EMG12</th>\n",
       "      <th>EMG13</th>\n",
       "      <th>EMG14</th>\n",
       "      <th>EMG15</th>\n",
       "      <th>EMG16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P102</td>\n",
       "      <td>pan</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.362743</td>\n",
       "      <td>-0.801651</td>\n",
       "      <td>-0.383077</td>\n",
       "      <td>-0.195299</td>\n",
       "      <td>-0.203047</td>\n",
       "      <td>-0.464472</td>\n",
       "      <td>-0.276292</td>\n",
       "      <td>-0.026736</td>\n",
       "      <td>-0.873870</td>\n",
       "      <td>-1.036152</td>\n",
       "      <td>-0.580930</td>\n",
       "      <td>-0.719494</td>\n",
       "      <td>-0.502255</td>\n",
       "      <td>-1.750091</td>\n",
       "      <td>-0.127847</td>\n",
       "      <td>-0.094192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P102</td>\n",
       "      <td>pan</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.351553</td>\n",
       "      <td>-0.775334</td>\n",
       "      <td>-0.382545</td>\n",
       "      <td>-0.154773</td>\n",
       "      <td>-0.131977</td>\n",
       "      <td>-0.295204</td>\n",
       "      <td>-0.125822</td>\n",
       "      <td>0.089679</td>\n",
       "      <td>-0.816215</td>\n",
       "      <td>-2.082635</td>\n",
       "      <td>-0.006283</td>\n",
       "      <td>-0.139439</td>\n",
       "      <td>-0.367764</td>\n",
       "      <td>-0.208084</td>\n",
       "      <td>-0.111811</td>\n",
       "      <td>-0.039009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P102</td>\n",
       "      <td>pan</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.380825</td>\n",
       "      <td>-0.762588</td>\n",
       "      <td>-0.398388</td>\n",
       "      <td>-0.085411</td>\n",
       "      <td>0.017528</td>\n",
       "      <td>-0.205675</td>\n",
       "      <td>-0.068451</td>\n",
       "      <td>0.117076</td>\n",
       "      <td>-0.668221</td>\n",
       "      <td>-3.403064</td>\n",
       "      <td>-0.526030</td>\n",
       "      <td>-0.478294</td>\n",
       "      <td>-0.300443</td>\n",
       "      <td>0.203266</td>\n",
       "      <td>0.113300</td>\n",
       "      <td>0.004728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P102</td>\n",
       "      <td>pan</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.366795</td>\n",
       "      <td>-0.765464</td>\n",
       "      <td>-0.374423</td>\n",
       "      <td>-0.073225</td>\n",
       "      <td>0.183172</td>\n",
       "      <td>0.009277</td>\n",
       "      <td>-0.058907</td>\n",
       "      <td>0.080977</td>\n",
       "      <td>-0.424416</td>\n",
       "      <td>-3.709413</td>\n",
       "      <td>-0.570894</td>\n",
       "      <td>-0.775155</td>\n",
       "      <td>-0.144710</td>\n",
       "      <td>-0.619539</td>\n",
       "      <td>0.146499</td>\n",
       "      <td>0.199975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P102</td>\n",
       "      <td>pan</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.245578</td>\n",
       "      <td>-0.761283</td>\n",
       "      <td>-0.303976</td>\n",
       "      <td>-0.081947</td>\n",
       "      <td>0.224996</td>\n",
       "      <td>0.103319</td>\n",
       "      <td>-0.003929</td>\n",
       "      <td>0.041526</td>\n",
       "      <td>-0.016530</td>\n",
       "      <td>-4.075150</td>\n",
       "      <td>-0.127710</td>\n",
       "      <td>2.682791</td>\n",
       "      <td>-0.141750</td>\n",
       "      <td>-0.208404</td>\n",
       "      <td>-0.035642</td>\n",
       "      <td>0.172662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant Gesture_ID Gesture_Num      EMG1      EMG2      EMG3      EMG4   \n",
       "0        P102        pan           1 -0.362743 -0.801651 -0.383077 -0.195299  \\\n",
       "1        P102        pan           1 -0.351553 -0.775334 -0.382545 -0.154773   \n",
       "2        P102        pan           1 -0.380825 -0.762588 -0.398388 -0.085411   \n",
       "3        P102        pan           1 -0.366795 -0.765464 -0.374423 -0.073225   \n",
       "4        P102        pan           1 -0.245578 -0.761283 -0.303976 -0.081947   \n",
       "\n",
       "       EMG5      EMG6      EMG7      EMG8      EMG9     EMG10     EMG11   \n",
       "0 -0.203047 -0.464472 -0.276292 -0.026736 -0.873870 -1.036152 -0.580930  \\\n",
       "1 -0.131977 -0.295204 -0.125822  0.089679 -0.816215 -2.082635 -0.006283   \n",
       "2  0.017528 -0.205675 -0.068451  0.117076 -0.668221 -3.403064 -0.526030   \n",
       "3  0.183172  0.009277 -0.058907  0.080977 -0.424416 -3.709413 -0.570894   \n",
       "4  0.224996  0.103319 -0.003929  0.041526 -0.016530 -4.075150 -0.127710   \n",
       "\n",
       "      EMG12     EMG13     EMG14     EMG15     EMG16  \n",
       "0 -0.719494 -0.502255 -1.750091 -0.127847 -0.094192  \n",
       "1 -0.139439 -0.367764 -0.208084 -0.111811 -0.039009  \n",
       "2 -0.478294 -0.300443  0.203266  0.113300  0.004728  \n",
       "3 -0.775155 -0.144710 -0.619539  0.146499  0.199975  \n",
       "4  2.682791 -0.141750 -0.208404 -0.035642  0.172662  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(raw_userdef_data_df.shape)\n",
    "raw_userdef_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0375f2f",
   "metadata": {},
   "source": [
    " As a preliminary step, we can simulate each user training a gesture classification model using solely their own dataset. We can then execute a pairwise comparison, where we test each user’s model and every other user’s dataset, and report the score. At this point, we can begin a agglomerative clustering procedure, by either clustering the two users with the highest corresponding scores, or by clustering all users that achieved above some minimum cross-subject classification accuracy. Then, we can repeat this procedure on the newly formed clusters, this time training a single model over all the data in the given cluster. By repeating this process until only one model remains, we can generate a dendrogram showing which users are best clustered in order to train cluster-level models. One issue with this approach is that as the clusters grow, the training sets will grow in tandem. To a limited extent, this can be offset by limiting all dataset sizes to the size of single user’s dataset and having the cluster model train on a random sample of gestures. An alternative approach would be to enforce all users into clusters of the same size each round, so that all clusters have the same dataset size, although this would artificially create many clusters. However, we also expect to have the opposite problem, as in myprevious works I have shown that cross-subject models typically perform poorly in general for these types of tasks, e.g. that training over multiple users will likely only grant modest improvements in performance, if any (especially if fixing the training dataset size). The goal of this procedure is to yield clusters for which the internal cluster model performs better than any of the intra-subject models within the cluster. Even if the internal cluster model does not outperform all intra-subject models, as long as it reduces the calibration / number of samples required from a novel user, this is still a success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ade3f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant</th>\n",
       "      <th>Gesture_ID</th>\n",
       "      <th>Gesture_Num</th>\n",
       "      <th>feature</th>\n",
       "      <th>Gesture_Encoded</th>\n",
       "      <th>Cluster_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P004</td>\n",
       "      <td>close</td>\n",
       "      <td>1</td>\n",
       "      <td>[[6.079045311063784], [-7.551458873254243], [-...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P004</td>\n",
       "      <td>close</td>\n",
       "      <td>10</td>\n",
       "      <td>[[5.994789910363704], [-7.978871468164499], [-...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P004</td>\n",
       "      <td>close</td>\n",
       "      <td>2</td>\n",
       "      <td>[[6.010193380499154], [-7.7063875553339], [-20...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P004</td>\n",
       "      <td>close</td>\n",
       "      <td>3</td>\n",
       "      <td>[[5.8212078257286874], [-7.463908156909893], [...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P004</td>\n",
       "      <td>close</td>\n",
       "      <td>4</td>\n",
       "      <td>[[5.974675085061773], [-7.945111601415482], [-...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant Gesture_ID Gesture_Num   \n",
       "0        P004      close           1  \\\n",
       "1        P004      close          10   \n",
       "2        P004      close           2   \n",
       "3        P004      close           3   \n",
       "4        P004      close           4   \n",
       "\n",
       "                                             feature  Gesture_Encoded   \n",
       "0  [[6.079045311063784], [-7.551458873254243], [-...                0  \\\n",
       "1  [[5.994789910363704], [-7.978871468164499], [-...                0   \n",
       "2  [[6.010193380499154], [-7.7063875553339], [-20...                0   \n",
       "3  [[5.8212078257286874], [-7.463908156909893], [...                0   \n",
       "4  [[5.974675085061773], [-7.945111601415482], [-...                0   \n",
       "\n",
       "   Cluster_ID  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 1: Train a classification model on every single individual user\n",
    "\n",
    "userdef_df = raw_userdef_data_df.groupby(['Participant', 'Gesture_ID', 'Gesture_Num']).apply(create_feature_vectors)\n",
    "#output is df with particpant, gesture_ID, gesture_num and feature (holds 80 len vector)\n",
    "userdef_df = userdef_df.reset_index(drop=True)\n",
    "\n",
    "#convert Gesture_ID to numerical with new Gesture_Encoded column\n",
    "label_encoder = LabelEncoder()\n",
    "userdef_df['Gesture_Encoded'] = label_encoder.fit_transform(userdef_df['Gesture_ID'])\n",
    "\n",
    "label_encoder2 = LabelEncoder()\n",
    "userdef_df['Cluster_ID'] = label_encoder2.fit_transform(userdef_df['Participant'])\n",
    "\n",
    "print(userdef_df.shape)\n",
    "userdef_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7fa64dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['P004', 'P005', 'P006', 'P008', 'P010', 'P011', 'P102', 'P103',\n",
       "       'P104', 'P105', 'P106', 'P107', 'P108', 'P109', 'P110', 'P111',\n",
       "       'P112', 'P114', 'P115', 'P116', 'P118', 'P119', 'P121', 'P122',\n",
       "       'P123', 'P124', 'P125', 'P126', 'P127', 'P128', 'P131', 'P132'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userdef_df['Participant'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b24f4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agglo_merge_with_joint_training(userdef_df, model, n_splits=3, target_column=\"Gesture_Encoded\", feature_column=\"feature\", cluster_column=\"Cluster_ID\"):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - userdef_df (DataFrame): Data containing the clusters and features.\n",
    "    - model (str or sklearn model object): The model to train. If string, it must be one of:\n",
    "      ['LogisticRegression', 'SVC', 'RF', 'GradientBoosting', 'KNN'].\n",
    "\n",
    "    Returns:\n",
    "    - merge_log: List of tuples tracking merge actions and performance.\n",
    "    - intra_cluster_performance: Performance of models trained on individual clusters.\n",
    "    \"\"\"\n",
    "    # Mapping model names to objects\n",
    "    model_map = {\n",
    "        'LogisticRegression': LogisticRegression(random_state=42),\n",
    "        'SVC': SVC(kernel='rbf', random_state=42),\n",
    "        'RF': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        'GradientBoosting': GradientBoostingClassifier(random_state=42),\n",
    "        'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    }\n",
    "\n",
    "    if isinstance(model, str):\n",
    "        if model not in model_map:\n",
    "            raise ValueError(f\"Unsupported model: {model}. Choose from {list(model_map.keys())}.\")\n",
    "        base_model = model_map[model]\n",
    "    else:\n",
    "        base_model = model\n",
    "\n",
    "    intra_cluster_performance = {}  # Performance of models trained on individual clusters\n",
    "    total_val_accuracy = 0\n",
    "    #num_folds_processed = 0\n",
    "    clus_model_lst = []\n",
    "    # Initialize cluster performances\n",
    "    for cluster_id in userdef_df['Cluster_ID'].unique():\n",
    "        # Filter data for the current cluster\n",
    "        cluster_data = userdef_df[userdef_df[cluster_column] == cluster_id]\n",
    "        X = np.array([x.flatten() for x in cluster_data[feature_column]])\n",
    "        y = np.array(cluster_data[target_column])\n",
    "\n",
    "        # Stratified K-Fold for validation splits\n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        cluster_val_accuracy = 0\n",
    "\n",
    "        for train_idx, val_idx in skf.split(X, y):\n",
    "            X_train, X_val = X[train_idx], X[val_idx]\n",
    "            y_train, y_val = y[train_idx], y[val_idx]\n",
    "            # Create a fresh model for each fold\n",
    "            fold_model = base_model.__class__(**base_model.get_params())\n",
    "            fold_model.fit(X_train, y_train)\n",
    "            # Predict on the validation set and calculate accuracy\n",
    "            y_pred = fold_model.predict(X_val)\n",
    "            cluster_val_accuracy += accuracy_score(y_val, y_pred)\n",
    "            \n",
    "        clus_model_lst.append(fold_model)\n",
    "        # Average accuracy for this cluster\n",
    "        cluster_val_accuracy /= n_splits\n",
    "        # I think this really ought to append not add...\n",
    "        ## TOTAL maintains the acc of the entire process (across all clusters)\n",
    "        total_val_accuracy += cluster_val_accuracy\n",
    "        #num_folds_processed += 1  # This isn't even initialized\n",
    "        \n",
    "        # Should this be total_val_accuracy or cluster_val_accuracy...\n",
    "        ## From ChatGPT's code (that wasnt using crossval) it looks like it should be cluster_val_accuracy?\n",
    "        ## I am not sure why cluster val acc is being summed into total_val_acc...\n",
    "        intra_cluster_performance[cluster_id] = cluster_val_accuracy\n",
    "\n",
    "    iterations = 0\n",
    "    merge_log = []  # Log of merges\n",
    "    while len(userdef_df['Cluster_ID'].unique()) > 1:\n",
    "        print(f\"{len(userdef_df['Cluster_ID'].unique())} Clusters Remaining\")\n",
    "        current_clusters = userdef_df['Cluster_ID'].unique()\n",
    "        best_merge = None  # Track the best merge\n",
    "        best_performance = -np.inf\n",
    "        \n",
    "        # Track processed cluster pairs\n",
    "        processed_pairs = set()\n",
    "        # Evaluate all cluster pairs\n",
    "        for i, cluster_a in enumerate(current_clusters):\n",
    "            for cluster_b in current_clusters[i + 1:]:  # Is this gonna break when a is the last cluster...\n",
    "                \n",
    "                # Skip if the pair has already been processed\n",
    "                if (cluster_a, cluster_b) in processed_pairs or (cluster_b, cluster_a) in processed_pairs:\n",
    "                    continue\n",
    "                else:\n",
    "                    # Add the pair to the set of processed pairs\n",
    "                    processed_pairs.add((cluster_a, cluster_b))\n",
    "\n",
    "                # Stratified K-Fold for validation splits\n",
    "                ## Do I need to run this every loop?\n",
    "                skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "                \n",
    "                # Filter data for the current cluster\n",
    "                ## I think I should do this for both clusters, create both cluster train/tests, then combine them afterwards\n",
    "                cluster_a_data = userdef_df[userdef_df[cluster_column] == cluster_a]\n",
    "                Xa = np.array([x.flatten() for x in cluster_a_data[feature_column]])\n",
    "                ya = np.array(cluster_a_data[target_column])\n",
    "                \n",
    "                cluster_b_data = userdef_df[userdef_df[cluster_column] == cluster_b]\n",
    "                Xb = np.array([x.flatten() for x in cluster_b_data[feature_column]])\n",
    "                yb = np.array(cluster_b_data[target_column])\n",
    "\n",
    "                pair_val_accuracy = 0\n",
    "                for train_idx, val_idx in skf.split(X, y):\n",
    "                    Xa_train, Xa_val = Xa[train_idx], Xa[val_idx]\n",
    "                    ya_train, ya_val = ya[train_idx], ya[val_idx]\n",
    "                    Xb_train, Xb_val = Xb[train_idx], Xb[val_idx]\n",
    "                    yb_train, yb_val = yb[train_idx], yb[val_idx]\n",
    "                    # CONCAT HERE!\n",
    "                    X_train = np.concatenate([Xa_train, Xb_train], axis=0)\n",
    "                    X_val = np.concatenate([Xa_val, Xb_val], axis=0)\n",
    "                    y_train = np.concatenate([ya_train, yb_train], axis=0)\n",
    "                    y_val = np.concatenate([ya_val, yb_val], axis=0)\n",
    "                    # Create a fresh model for each fold\n",
    "                    fold_model = base_model.__class__(**base_model.get_params())\n",
    "                    fold_model.fit(X_train, y_train)\n",
    "                    # Predict on the validation set and calculate accuracy\n",
    "                    y_pred = fold_model.predict(X_val)\n",
    "                    pair_val_accuracy += accuracy_score(y_val, y_pred)\n",
    "                    \n",
    "                avg_clus_pair_acc_across_folds = pair_val_accuracy / n_splits\n",
    "\n",
    "                # Check if merging improves performance\n",
    "                if (\n",
    "                    avg_clus_pair_acc_across_folds > best_performance and \n",
    "                    avg_clus_pair_acc_across_folds > intra_cluster_performance[cluster_a] and\n",
    "                    avg_clus_pair_acc_across_folds > intra_cluster_performance[cluster_b]\n",
    "                ):\n",
    "                    best_performance = avg_clus_pair_acc_across_folds\n",
    "                    best_merge = (cluster_a, cluster_b)\n",
    "\n",
    "        if not best_merge:\n",
    "            print(\"No further merges improve performance. Stopping.\")\n",
    "            break\n",
    "\n",
    "        # Perform the best merge\n",
    "        cluster_a, cluster_b = best_merge\n",
    "        new_cluster_id = max(current_clusters) + 1\n",
    "        userdef_df.loc[userdef_df['Cluster_ID'].isin([cluster_a, cluster_b]), 'Cluster_ID'] = new_cluster_id\n",
    "\n",
    "        # Log the merge\n",
    "        merge_log.append((iterations, cluster_a, cluster_b, best_performance, new_cluster_id))\n",
    "\n",
    "        # Update performance\n",
    "        intra_cluster_performance[new_cluster_id] = best_performance\n",
    "        del intra_cluster_performance[cluster_a]\n",
    "        del intra_cluster_performance[cluster_b]\n",
    "\n",
    "        iterations += 1\n",
    "\n",
    "    return merge_log, intra_cluster_performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4b7832d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 Clusters Remaining\n",
      "31 Clusters Remaining\n",
      "30 Clusters Remaining\n",
      "29 Clusters Remaining\n",
      "28 Clusters Remaining\n",
      "No further merges improve performance. Stopping.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m merge_log, intra_cluster_performance, cross_cluster_performance \u001b[38;5;241m=\u001b[39m agglo_merge_with_joint_training(userdef_df, model_str)\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "merge_log, intra_cluster_performance, cross_cluster_performance = agglo_merge_with_joint_training(userdef_df, model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af48c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37c3562",
   "metadata": {},
   "source": [
    "## INTRA CLUSTER RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0a813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for cluster_id in intra_cluster_performance:\n",
    "    # Extract valid iterations and performance\n",
    "    data = intra_cluster_performance[cluster_id]\n",
    "    valid_iterations = [it for it, perf in data if perf is not None]\n",
    "    valid_performance = [perf for it, perf in data if perf is not None]\n",
    "    if valid_iterations[0]==0:\n",
    "        continue\n",
    "    #print(valid_iterations)\n",
    "    #print(valid_performance)\n",
    "    #print()\n",
    "    plt.plot(valid_iterations, valid_performance, label=f\"Cluster {cluster_id}\")\n",
    "\n",
    "plt.xlabel(\"Iteration\", fontsize=18)\n",
    "plt.ylabel(\"Intra-Cluster Test Accuracy\", fontsize=18)\n",
    "plt.title(f\"{model_str} Intra-Cluster Acc: Merged Clusters Only\", fontsize=18)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7fff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for cluster_id in intra_cluster_performance:\n",
    "    # Extract valid iterations and performance\n",
    "    data = intra_cluster_performance[cluster_id]\n",
    "    valid_iterations = [it for it, perf in data if perf is not None]\n",
    "    valid_performance = [perf for it, perf in data if perf is not None]\n",
    "    if valid_iterations[0]!=0:\n",
    "        continue\n",
    "    #print(valid_iterations)\n",
    "    #print(valid_performance)\n",
    "    #print()\n",
    "    plt.plot(valid_iterations, valid_performance, label=f\"Cluster {cluster_id}\")\n",
    "\n",
    "plt.xlabel(\"Iteration\", fontsize=18)\n",
    "plt.ylabel(\"Intra-Cluster Test Accuracy\", fontsize=18)\n",
    "plt.title(f\"{model_str} Intra-Cluster Acc: Original Clusters Only\", fontsize=18)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f3f61a",
   "metadata": {},
   "source": [
    "## CROSS CLUSTER RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3349da89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for cluster_id in cross_cluster_performance:\n",
    "    # Extract valid iterations and performance\n",
    "    data = cross_cluster_performance[cluster_id]\n",
    "    valid_iterations = [it for it, perf in data if perf is not None]\n",
    "    valid_performance = [perf for it, perf in data if perf is not None]\n",
    "    if valid_iterations[0]==0:\n",
    "        continue\n",
    "    #print(valid_iterations)\n",
    "    #print(valid_performance)\n",
    "    #print()\n",
    "    plt.plot(valid_iterations, valid_performance, label=f\"Cluster {cluster_id}\")\n",
    "\n",
    "plt.xlabel(\"Iteration\", fontsize=18)\n",
    "plt.ylabel(\"Cross-Cluster Test Accuracy\", fontsize=18)\n",
    "plt.title(f\"{model_str} Cross-Cluster Acc: Merged Clusters Only\", fontsize=18)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a882bc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for cluster_id in cross_cluster_performance:\n",
    "    # Extract valid iterations and performance\n",
    "    data = cross_cluster_performance[cluster_id]\n",
    "    valid_iterations = [it for it, perf in data if perf is not None]\n",
    "    valid_performance = [perf for it, perf in data if perf is not None]\n",
    "    if valid_iterations[0]!=0:\n",
    "        continue\n",
    "    #print(valid_iterations)\n",
    "    #print(valid_performance)\n",
    "    #print()\n",
    "    plt.plot(valid_iterations, valid_performance, label=f\"Cluster {cluster_id}\")\n",
    "\n",
    "plt.xlabel(\"Iteration\", fontsize=18)\n",
    "plt.ylabel(\"Cross-Cluster Test Accuracy\", fontsize=18)\n",
    "plt.title(f\"{model_str} Cross-Cluster Acc: Original Clusters Only\", fontsize=18)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db152ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "n = 5\n",
    "\n",
    "# Reduce number of lines (e.g., top n longest-lived clusters)\n",
    "longest_clusters = sorted(cross_cluster_performance.keys(), key=lambda k: len(cross_cluster_performance[k]), reverse=True)[:n]\n",
    "\n",
    "for cluster_id in longest_clusters:\n",
    "    # Extract valid iterations and performance\n",
    "    data = cross_cluster_performance[cluster_id]\n",
    "    valid_iterations = [it for it, perf in data if perf is not None]\n",
    "    valid_performance = [perf for it, perf in data if perf is not None]\n",
    "    plt.plot(valid_iterations, valid_performance, label=f\"Cluster {cluster_id}\")\n",
    "\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Cross-Cluster Test Accuracy\")\n",
    "plt.title(f\"Cross-Cluster Test Accuracy: {n} Longest-Lasting Clusters\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a98b568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "n = 5  # Number of clusters to plot\n",
    "\n",
    "# Find clusters with the highest final accuracies\n",
    "highest_final_accuracy_clusters = sorted(\n",
    "    cross_cluster_performance.keys(), \n",
    "    key=lambda k: max([perf for it, perf in cross_cluster_performance[k] if perf is not None], default=0), \n",
    "    reverse=True\n",
    ")[:n]\n",
    "\n",
    "# Plot the performance curves for these clusters\n",
    "for cluster_id in highest_final_accuracy_clusters:\n",
    "    # Extract valid iterations and performance\n",
    "    data = cross_cluster_performance[cluster_id]\n",
    "    valid_iterations = [it for it, perf in data if perf is not None]\n",
    "    valid_performance = [perf for it, perf in data if perf is not None]\n",
    "    plt.plot(valid_iterations, valid_performance, label=f\"Cluster {cluster_id}\")\n",
    "\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Cross-Cluster Test Accuracy\")\n",
    "plt.title(f\"Cross-Cluster Test Accuracy: {n} Clusters with Highest Final Accuracy\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbd2293",
   "metadata": {},
   "source": [
    "## Intra-Cluster Test Accuracy Merge Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf8842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization with Merge Log and Connections\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Dictionary to track the last valid point for each cluster\n",
    "last_points = {}\n",
    "\n",
    "# Plot original clusters\n",
    "for cluster_id in cross_cluster_performance:\n",
    "    data = cross_cluster_performance[cluster_id]\n",
    "    valid_iterations = [it for it, perf in data if perf is not None]\n",
    "    valid_performance = [perf for it, perf in data if perf is not None]\n",
    "    if valid_iterations[0] != 0:\n",
    "        continue\n",
    "\n",
    "    # Plot original cluster performance\n",
    "    plt.plot(valid_iterations, valid_performance, label=f\"Cluster {cluster_id}\")\n",
    "    last_points[cluster_id] = (valid_iterations[-1], valid_performance[-1])  # Store the last point\n",
    "\n",
    "# Handle merged clusters and connect original clusters\n",
    "for iteration, cluster1, cluster2, _, new_cluster in merge_log:\n",
    "    # Plot and connect the merged clusters\n",
    "    for cluster in [cluster1, cluster2]:\n",
    "        if cluster in cross_cluster_performance:\n",
    "            data = cross_cluster_performance[cluster]\n",
    "            merge_perf = next((perf for it, perf in data if it == iteration), None)\n",
    "            if merge_perf is not None:\n",
    "                plt.scatter(iteration, merge_perf, color='red', marker='^')#, label=f\"Merge {cluster} → {new_cluster}\")\n",
    "                \n",
    "        if cluster in last_points:  # If it's an original cluster\n",
    "            last_iteration, last_perf = last_points[cluster]\n",
    "\n",
    "            # Connect to the newly merged cluster\n",
    "            if new_cluster in cross_cluster_performance:\n",
    "                new_data = cross_cluster_performance[new_cluster]\n",
    "                valid_iterations = [it for it, perf in new_data if perf is not None and it >= iteration]\n",
    "                valid_performance = [perf for it, perf in new_data if perf is not None and it >= iteration]\n",
    "\n",
    "                if valid_iterations:\n",
    "                    # Draw a line connecting the original cluster to the new merged cluster\n",
    "                    plt.plot(\n",
    "                        [last_iteration, valid_iterations[0]],\n",
    "                        [last_perf, valid_performance[0]],\n",
    "                        linestyle='--', color='gray'\n",
    "                    )\n",
    "\n",
    "                    # Continue plotting the merged cluster's performance\n",
    "                    plt.plot(valid_iterations, valid_performance, linestyle='--')\n",
    "\n",
    "                # Update the last points for the newly merged cluster\n",
    "                if valid_iterations:\n",
    "                    last_points[new_cluster] = (valid_iterations[-1], valid_performance[-1])\n",
    "\n",
    "# Add labels, legend, and formatting\n",
    "plt.xlabel(\"Iteration\", fontsize=18)\n",
    "plt.ylabel(\"Cross-Cluster Test Accuracy\", fontsize=18)\n",
    "plt.title(f\"{model_str} Cross-Cluster Acc with Merge Connections\", fontsize=18)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6a0280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization with Merge Log and Connections\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Dictionary to track the last valid point for each cluster\n",
    "last_points = {}\n",
    "\n",
    "# Plot original clusters\n",
    "for cluster_id in intra_cluster_performance:\n",
    "    data = intra_cluster_performance[cluster_id]\n",
    "    valid_iterations = [it for it, perf in data if perf is not None]\n",
    "    valid_performance = [perf for it, perf in data if perf is not None]\n",
    "    if valid_iterations[0] != 0:\n",
    "        continue\n",
    "\n",
    "    # Plot original cluster performance\n",
    "    plt.plot(valid_iterations, valid_performance, label=f\"Cluster {cluster_id}\")\n",
    "    last_points[cluster_id] = (valid_iterations[-1], valid_performance[-1])  # Store the last point\n",
    "\n",
    "# Handle merged clusters and connect original clusters\n",
    "for iteration, cluster1, cluster2, _, new_cluster in merge_log:\n",
    "    # Plot and connect the merged clusters\n",
    "    for cluster in [cluster1, cluster2]:\n",
    "        if cluster in intra_cluster_performance:\n",
    "            data = intra_cluster_performance[cluster]\n",
    "            merge_perf = next((perf for it, perf in data if it == iteration), None)\n",
    "            if merge_perf is not None:\n",
    "                plt.scatter(iteration, merge_perf, color='red', marker='^')#, label=f\"Merge {cluster} → {new_cluster}\")\n",
    "                \n",
    "        if cluster in last_points:  # If it's an original cluster\n",
    "            last_iteration, last_perf = last_points[cluster]\n",
    "\n",
    "            # Connect to the newly merged cluster\n",
    "            if new_cluster in intra_cluster_performance:\n",
    "                new_data = intra_cluster_performance[new_cluster]\n",
    "                valid_iterations = [it for it, perf in new_data if perf is not None and it >= iteration]\n",
    "                valid_performance = [perf for it, perf in new_data if perf is not None and it >= iteration]\n",
    "\n",
    "                if valid_iterations:\n",
    "                    # Draw a line connecting the original cluster to the new merged cluster\n",
    "                    plt.plot(\n",
    "                        [last_iteration, valid_iterations[0]],\n",
    "                        [last_perf, valid_performance[0]],\n",
    "                        linestyle='--', color='gray'\n",
    "                    )\n",
    "\n",
    "                    # Continue plotting the merged cluster's performance\n",
    "                    plt.plot(valid_iterations, valid_performance, linestyle='--')\n",
    "\n",
    "                # Update the last points for the newly merged cluster\n",
    "                if valid_iterations:\n",
    "                    last_points[new_cluster] = (valid_iterations[-1], valid_performance[-1])\n",
    "\n",
    "# Add labels, legend, and formatting\n",
    "plt.xlabel(\"Iteration\", fontsize=18)\n",
    "plt.ylabel(\"Intra-Cluster Test Accuracy\", fontsize=18)\n",
    "plt.title(f\"{model_str} Intra-Cluster Acc with Merge Connections\", fontsize=18)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89b30c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "intra_mean_lst, cross_mean_lst, ratio_lst = compute_performance_ratios(intra_cluster_performance, cross_cluster_performance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7654b605",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(intra_mean_lst[31:], label=\"Intra Mean\")\n",
    "plt.plot(cross_mean_lst[31:], label=\"Cross Mean\")\n",
    "plt.plot((np.array(ratio_lst)/10)[31:], label=\"Ratio/10\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel(\"Iteration\", fontsize=18)\n",
    "plt.ylabel(\"Mean Accuracy | Ratio/10\", fontsize=18)\n",
    "plt.title(f\"{model_str} Summary Statistic Trends\", fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5844d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
