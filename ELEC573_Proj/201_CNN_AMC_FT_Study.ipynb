{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c0fef36",
   "metadata": {},
   "source": [
    "> __Purpose:__ This NB tests a CNN in the agglomerative model clustering procedure. With later finetuning. Uses the previously developed PyTorch code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "012267e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_str = \"CNN\"\n",
    "# Train/test user split: 24/8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a62336d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory:  c:\\Users\\kdmen\\Repos\\fl-gestures\\ELEC573_Proj\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import torch\n",
    "\n",
    "np.random.seed(42) \n",
    "\n",
    "from moments_engr import *\n",
    "from agglo_model_clust import *\n",
    "from cluster_acc_viz_funcs import *\n",
    "from DNN_FT_funcs import *\n",
    "from DNN_AMC_funcs import *\n",
    "from model_classes import *\n",
    "\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(\"Current Working Directory: \", cwd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33b80c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(204800, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant</th>\n",
       "      <th>Gesture_ID</th>\n",
       "      <th>Gesture_Num</th>\n",
       "      <th>EMG1</th>\n",
       "      <th>EMG2</th>\n",
       "      <th>EMG3</th>\n",
       "      <th>EMG4</th>\n",
       "      <th>EMG5</th>\n",
       "      <th>EMG6</th>\n",
       "      <th>EMG7</th>\n",
       "      <th>EMG8</th>\n",
       "      <th>EMG9</th>\n",
       "      <th>EMG10</th>\n",
       "      <th>EMG11</th>\n",
       "      <th>EMG12</th>\n",
       "      <th>EMG13</th>\n",
       "      <th>EMG14</th>\n",
       "      <th>EMG15</th>\n",
       "      <th>EMG16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P102</td>\n",
       "      <td>pan</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.362743</td>\n",
       "      <td>-0.801651</td>\n",
       "      <td>-0.383077</td>\n",
       "      <td>-0.195299</td>\n",
       "      <td>-0.203047</td>\n",
       "      <td>-0.464472</td>\n",
       "      <td>-0.276292</td>\n",
       "      <td>-0.026736</td>\n",
       "      <td>-0.873870</td>\n",
       "      <td>-1.036152</td>\n",
       "      <td>-0.580930</td>\n",
       "      <td>-0.719494</td>\n",
       "      <td>-0.502255</td>\n",
       "      <td>-1.750091</td>\n",
       "      <td>-0.127847</td>\n",
       "      <td>-0.094192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P102</td>\n",
       "      <td>pan</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.351553</td>\n",
       "      <td>-0.775334</td>\n",
       "      <td>-0.382545</td>\n",
       "      <td>-0.154773</td>\n",
       "      <td>-0.131977</td>\n",
       "      <td>-0.295204</td>\n",
       "      <td>-0.125822</td>\n",
       "      <td>0.089679</td>\n",
       "      <td>-0.816215</td>\n",
       "      <td>-2.082635</td>\n",
       "      <td>-0.006283</td>\n",
       "      <td>-0.139439</td>\n",
       "      <td>-0.367764</td>\n",
       "      <td>-0.208084</td>\n",
       "      <td>-0.111811</td>\n",
       "      <td>-0.039009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P102</td>\n",
       "      <td>pan</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.380825</td>\n",
       "      <td>-0.762588</td>\n",
       "      <td>-0.398388</td>\n",
       "      <td>-0.085411</td>\n",
       "      <td>0.017528</td>\n",
       "      <td>-0.205675</td>\n",
       "      <td>-0.068451</td>\n",
       "      <td>0.117076</td>\n",
       "      <td>-0.668221</td>\n",
       "      <td>-3.403064</td>\n",
       "      <td>-0.526030</td>\n",
       "      <td>-0.478294</td>\n",
       "      <td>-0.300443</td>\n",
       "      <td>0.203266</td>\n",
       "      <td>0.113300</td>\n",
       "      <td>0.004728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P102</td>\n",
       "      <td>pan</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.366795</td>\n",
       "      <td>-0.765464</td>\n",
       "      <td>-0.374423</td>\n",
       "      <td>-0.073225</td>\n",
       "      <td>0.183172</td>\n",
       "      <td>0.009277</td>\n",
       "      <td>-0.058907</td>\n",
       "      <td>0.080977</td>\n",
       "      <td>-0.424416</td>\n",
       "      <td>-3.709413</td>\n",
       "      <td>-0.570894</td>\n",
       "      <td>-0.775155</td>\n",
       "      <td>-0.144710</td>\n",
       "      <td>-0.619539</td>\n",
       "      <td>0.146499</td>\n",
       "      <td>0.199975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P102</td>\n",
       "      <td>pan</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.245578</td>\n",
       "      <td>-0.761283</td>\n",
       "      <td>-0.303976</td>\n",
       "      <td>-0.081947</td>\n",
       "      <td>0.224996</td>\n",
       "      <td>0.103319</td>\n",
       "      <td>-0.003929</td>\n",
       "      <td>0.041526</td>\n",
       "      <td>-0.016530</td>\n",
       "      <td>-4.075150</td>\n",
       "      <td>-0.127710</td>\n",
       "      <td>2.682791</td>\n",
       "      <td>-0.141750</td>\n",
       "      <td>-0.208404</td>\n",
       "      <td>-0.035642</td>\n",
       "      <td>0.172662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant Gesture_ID Gesture_Num      EMG1      EMG2      EMG3      EMG4   \n",
       "0        P102        pan           1 -0.362743 -0.801651 -0.383077 -0.195299  \\\n",
       "1        P102        pan           1 -0.351553 -0.775334 -0.382545 -0.154773   \n",
       "2        P102        pan           1 -0.380825 -0.762588 -0.398388 -0.085411   \n",
       "3        P102        pan           1 -0.366795 -0.765464 -0.374423 -0.073225   \n",
       "4        P102        pan           1 -0.245578 -0.761283 -0.303976 -0.081947   \n",
       "\n",
       "       EMG5      EMG6      EMG7      EMG8      EMG9     EMG10     EMG11   \n",
       "0 -0.203047 -0.464472 -0.276292 -0.026736 -0.873870 -1.036152 -0.580930  \\\n",
       "1 -0.131977 -0.295204 -0.125822  0.089679 -0.816215 -2.082635 -0.006283   \n",
       "2  0.017528 -0.205675 -0.068451  0.117076 -0.668221 -3.403064 -0.526030   \n",
       "3  0.183172  0.009277 -0.058907  0.080977 -0.424416 -3.709413 -0.570894   \n",
       "4  0.224996  0.103319 -0.003929  0.041526 -0.016530 -4.075150 -0.127710   \n",
       "\n",
       "      EMG12     EMG13     EMG14     EMG15     EMG16  \n",
       "0 -0.719494 -0.502255 -1.750091 -0.127847 -0.094192  \n",
       "1 -0.139439 -0.367764 -0.208084 -0.111811 -0.039009  \n",
       "2 -0.478294 -0.300443  0.203266  0.113300  0.004728  \n",
       "3 -0.775155 -0.144710 -0.619539  0.146499  0.199975  \n",
       "4  2.682791 -0.141750 -0.208404 -0.035642  0.172662  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path1 = 'C:\\\\Users\\\\kdmen\\\\Box\\\\Meta_Gesture_2024\\\\saved_datasets\\\\filtered_datasets\\\\$BStand_EMG_df.pkl'\n",
    "\n",
    "with open(path1, 'rb') as file:\n",
    "    raw_userdef_data_df = pickle.load(file)  # (204800, 19)\n",
    "\n",
    "print(raw_userdef_data_df.shape)\n",
    "raw_userdef_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ade3f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant</th>\n",
       "      <th>Gesture_ID</th>\n",
       "      <th>Gesture_Num</th>\n",
       "      <th>feature</th>\n",
       "      <th>Gesture_Encoded</th>\n",
       "      <th>Cluster_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P004</td>\n",
       "      <td>close</td>\n",
       "      <td>1</td>\n",
       "      <td>[[6.079045311063784], [-7.551458873254243], [-...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P004</td>\n",
       "      <td>close</td>\n",
       "      <td>10</td>\n",
       "      <td>[[5.994789910363704], [-7.978871468164499], [-...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P004</td>\n",
       "      <td>close</td>\n",
       "      <td>2</td>\n",
       "      <td>[[6.010193380499154], [-7.7063875553339], [-20...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P004</td>\n",
       "      <td>close</td>\n",
       "      <td>3</td>\n",
       "      <td>[[5.8212078257286874], [-7.463908156909893], [...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P004</td>\n",
       "      <td>close</td>\n",
       "      <td>4</td>\n",
       "      <td>[[5.974675085061773], [-7.945111601415482], [-...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Participant Gesture_ID Gesture_Num   \n",
       "0        P004      close           1  \\\n",
       "1        P004      close          10   \n",
       "2        P004      close           2   \n",
       "3        P004      close           3   \n",
       "4        P004      close           4   \n",
       "\n",
       "                                             feature  Gesture_Encoded   \n",
       "0  [[6.079045311063784], [-7.551458873254243], [-...                0  \\\n",
       "1  [[5.994789910363704], [-7.978871468164499], [-...                0   \n",
       "2  [[6.010193380499154], [-7.7063875553339], [-20...                0   \n",
       "3  [[5.8212078257286874], [-7.463908156909893], [...                0   \n",
       "4  [[5.974675085061773], [-7.945111601415482], [-...                0   \n",
       "\n",
       "   Cluster_ID  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 1: Train a classification model on every single individual user\n",
    "\n",
    "userdef_df = raw_userdef_data_df.groupby(['Participant', 'Gesture_ID', 'Gesture_Num']).apply(create_feature_vectors)\n",
    "#output is df with particpant, gesture_ID, gesture_num and feature (holds 80 len vector)\n",
    "userdef_df = userdef_df.reset_index(drop=True)\n",
    "\n",
    "#convert Gesture_ID to numerical with new Gesture_Encoded column\n",
    "label_encoder = LabelEncoder()\n",
    "userdef_df['Gesture_Encoded'] = label_encoder.fit_transform(userdef_df['Gesture_ID'])\n",
    "\n",
    "label_encoder2 = LabelEncoder()\n",
    "userdef_df['Cluster_ID'] = label_encoder2.fit_transform(userdef_df['Participant'])\n",
    "\n",
    "print(userdef_df.shape)\n",
    "userdef_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7f2bf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_participants = userdef_df['Participant'].unique()\n",
    "# Shuffle the participants\n",
    "np.random.shuffle(all_participants)\n",
    "# Split into two groups\n",
    "#train_participants = all_participants[:24]  # First 24 participants\n",
    "test_participants = all_participants[24:]  # Remaining 8 participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb072fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "data_splits = prepare_data(\n",
    "    userdef_df, 'feature', 'Gesture_Encoded', \n",
    "    all_participants, test_participants, \n",
    "    training_trials_per_gesture=8, finetuning_trials_per_gesture=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7423158d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.DataFrame(data_splits['train']['feature'])\n",
    "# Create a new column 'features' that contains all 80 columns as lists\n",
    "features_df['feature'] = features_df.apply(lambda row: row.tolist(), axis=1)\n",
    "# Keep only the new combined column\n",
    "features_df = features_df[['feature']]\n",
    "# Combine with labels and participant_ids into a single DataFrame\n",
    "train_df = pd.concat([features_df, pd.Series(data_splits['train']['labels'], name='Gesture_Encoded'), pd.Series(data_splits['train']['participant_ids'], name='participant_ids')], axis=1)\n",
    "label_encoder = LabelEncoder()\n",
    "train_df['Cluster_ID'] = label_encoder.fit_transform(train_df['participant_ids'])\n",
    "\n",
    "features_df = pd.DataFrame(data_splits['intra_subject_test']['feature'])\n",
    "# Create a new column 'features' that contains all 80 columns as lists\n",
    "features_df['feature'] = features_df.apply(lambda row: row.tolist(), axis=1)\n",
    "# Keep only the new combined column\n",
    "features_df = features_df[['feature']]\n",
    "# Combine with labels and participant_ids into a single DataFrame\n",
    "test_df = pd.concat([features_df, pd.Series(data_splits['intra_subject_test']['labels'], name='Gesture_Encoded'), pd.Series(data_splits['intra_subject_test']['participant_ids'], name='participant_ids')], axis=1)\n",
    "label_encoder = LabelEncoder()\n",
    "test_df['Cluster_ID'] = label_encoder.fit_transform(test_df['participant_ids'])\n",
    "\n",
    "# ENTIRELY WITHHOLDING CROSS CLUSTER DATASET (NOVEL TEST SUBJECTS) FOR NOW. \n",
    "#test_df\n",
    "#features_df = pd.DataFrame(data_splits['train']['features'])\n",
    "## Create a new column 'features' that contains all 80 columns as lists\n",
    "#features_df['features'] = features_df.apply(lambda row: row.tolist(), axis=1)\n",
    "## Keep only the new combined column\n",
    "#features_df = features_df[['features']]\n",
    "## Combine with labels and participant_ids into a single DataFrame\n",
    "#train_df = pd.concat([features_df, pd.Series(data_splits['train']['labels'], name='Gesture_Encoded'), pd.Series(data_splits['train']['participant_ids'], name='participant_ids')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91d302fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dfs_dict = {'train':train_df, 'test':test_df}\n",
    "\n",
    "# Need to update Cluster_ID col at the end of each round, for both dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fab5959d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>Gesture_Encoded</th>\n",
       "      <th>participant_ids</th>\n",
       "      <th>Cluster_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[4.0728441780827485, -6.216633410388578, -15.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>P128</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[4.842766138855771, -7.933026853320965, -18.38...</td>\n",
       "      <td>0</td>\n",
       "      <td>P128</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[4.343725560839635, -6.20391996380322, -15.560...</td>\n",
       "      <td>0</td>\n",
       "      <td>P128</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[4.972292120731378, -6.996600730998998, -17.60...</td>\n",
       "      <td>0</td>\n",
       "      <td>P128</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[4.942130684716379, -6.513267267205743, -16.81...</td>\n",
       "      <td>0</td>\n",
       "      <td>P128</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature  Gesture_Encoded   \n",
       "0  [4.0728441780827485, -6.216633410388578, -15.0...                0  \\\n",
       "1  [4.842766138855771, -7.933026853320965, -18.38...                0   \n",
       "2  [4.343725560839635, -6.20391996380322, -15.560...                0   \n",
       "3  [4.972292120731378, -6.996600730998998, -17.60...                0   \n",
       "4  [4.942130684716379, -6.513267267205743, -16.81...                0   \n",
       "\n",
       "  participant_ids  Cluster_ID  \n",
       "0            P128          22  \n",
       "1            P128          22  \n",
       "2            P128          22  \n",
       "3            P128          22  \n",
       "4            P128          22  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbfe78a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: 24 Clusters Remaining\n",
      "Iter 1: 23 Clusters Remaining\n",
      "Iter 2: 22 Clusters Remaining\n",
      "Iter 3: 21 Clusters Remaining\n",
      "Iter 4: 20 Clusters Remaining\n",
      "Iter 5: 19 Clusters Remaining\n",
      "Iter 6: 18 Clusters Remaining\n",
      "Iter 7: 17 Clusters Remaining\n",
      "Iter 8: 16 Clusters Remaining\n",
      "Iter 9: 15 Clusters Remaining\n",
      "Iter 10: 14 Clusters Remaining\n",
      "Iter 11: 13 Clusters Remaining\n",
      "Iter 12: 12 Clusters Remaining\n",
      "Iter 13: 11 Clusters Remaining\n",
      "Iter 14: 10 Clusters Remaining\n",
      "Iter 15: 9 Clusters Remaining\n",
      "Iter 16: 8 Clusters Remaining\n",
      "Iter 17: 7 Clusters Remaining\n",
      "Iter 18: 6 Clusters Remaining\n",
      "Iter 19: 5 Clusters Remaining\n",
      "Iter 20: 4 Clusters Remaining\n",
      "Iter 21: 3 Clusters Remaining\n",
      "Iter 22: 2 Clusters Remaining\n"
     ]
    }
   ],
   "source": [
    "merge_log, intra_cluster_performance, cross_cluster_performance, nested_clus_model_dict = DNN_agglo_merge_procedure(data_dfs_dict, model_str, n_splits=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a84f81",
   "metadata": {},
   "source": [
    "# Finetuning Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7262f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_lst = list(nested_clus_model_dict['Iter18'].keys())\n",
    "print(\"Cluster list:\")\n",
    "print(cluster_lst)\n",
    "print()\n",
    "print(\"Cluster 41 model:\")\n",
    "print(nested_clus_model_dict['Iter18'][41])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39737416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATION\n",
    "\n",
    "# I would need to \n",
    "## 1) know which pids are in each cluster, at each merge iteration, \n",
    "## 2) bissect the datasets accordingly, \n",
    "## 3) create the trainloaders\n",
    "\n",
    "# And idk from which merge iteration I would report the results from...\n",
    "## Obv wouldnt want to show 30 iterations x 2-30 clusters per iter..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0b03cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WANT TO COMPARE THE MODEL PERFORMANCE ON THE NOVEL CLIENT PRE AND POST FT\n",
    "## VARY AMOUNT OF FT: \n",
    "## 1) hyperparams (epoch, lr, weight decay, dropout, etc) and \n",
    "## 2) how much data from novel_trainFT is used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd59a92",
   "metadata": {},
   "source": [
    "## Formalizing Procedure Into a Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68c54629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Path: c:\\Users\\kdmen\\Repos\\fl-gestures\\ELEC573_Proj\\models\\generic_CNN_model.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BEST PARAMS FOR GENERIC MODEL\n",
    "#lr=0.0001, bs=32, num_ep=50, adam, wd=0.0001, dr=0.3, num_conv=3, 32/64/128, k=5, s=2, m=1, bn=True\n",
    "config = {\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"batch_size\": 32,\n",
    "    \"num_epochs\": 50,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"dropout_rate\": 0.3,\n",
    "    \"num_conv_layers\": 3,\n",
    "    \"conv_layer_sizes\": [32, 64, 128], \n",
    "    \"kernel_size\": 5,\n",
    "    \"stride\": 2,\n",
    "    \"padding\": 1,\n",
    "    \"maxpool\": 1,\n",
    "    \"use_batchnorm\": True\n",
    "}\n",
    "\n",
    "#full_path = os.path.join(cwd, 'ELEC573_Proj', 'models', 'generic_CNN_model.pth')\n",
    "full_path = os.path.join(cwd, 'models', 'generic_CNN_model.pth')\n",
    "print(\"Full Path:\", full_path)\n",
    "\n",
    "# Load the pretrained model\n",
    "pretrained_generic_CNN_model = CNNModel_3layer(config, input_dim=80, num_classes=10)\n",
    "pretrained_generic_CNN_model.load_state_dict(torch.load(full_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d014b587",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_lst = list(nested_clus_model_dict['Iter18'].keys())\n",
    "print(\"Cluster list:\")\n",
    "print(cluster_lst)\n",
    "print()\n",
    "print(\"Cluster 41 model:\")\n",
    "print(nested_clus_model_dict['Iter18'][41])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d6f461fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "one_trial_data_splits = prepare_data(\n",
    "    userdef_df, 'feature', 'Gesture_Encoded', \n",
    "    all_participants, test_participants, \n",
    "    training_trials_per_gesture=1, finetuning_trials_per_gesture=1,\n",
    ")\n",
    "\n",
    "five_trial_data_splits = prepare_data(\n",
    "    userdef_df, 'feature', 'Gesture_Encoded', \n",
    "    all_participants, test_participants, \n",
    "    training_trials_per_gesture=5, finetuning_trials_per_gesture=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9410bb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PID P102, 0/8\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'participant_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m cross_test_loader \u001b[38;5;241m=\u001b[39m DataLoader(intra_test_dataset, batch_size\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m], shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m############## One Trial Cluster Assignment Dataset ##############\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m indices \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i, datasplit_pid \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mone_trial_data_splits\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparticipant_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;28;01mif\u001b[39;00m datasplit_pid \u001b[38;5;241m==\u001b[39m pid]\n\u001b[0;32m     31\u001b[0m clust_asgn_dataset \u001b[38;5;241m=\u001b[39m GestureDataset([one_trial_data_splits[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m'\u001b[39m][i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indices], [one_trial_data_splits[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m][i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indices])\n\u001b[0;32m     32\u001b[0m clust_asgn_loader \u001b[38;5;241m=\u001b[39m DataLoader(clust_asgn_dataset, batch_size\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m], shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'participant_ids'"
     ]
    }
   ],
   "source": [
    "train_pids = np.unique(data_splits['train']['participant_ids'])\n",
    "novel_participant_ft_data = data_splits['novel_trainFT']\n",
    "novel_participant_test_data = data_splits['cross_subject_test']\n",
    "novel_pids = np.unique(data_splits['novel_trainFT']['participant_ids'])\n",
    "num_local_training_epochs = 60\n",
    "num_ft_epochs = 50\n",
    "ft_lr = 0.001\n",
    "\n",
    "novel_pid_res_dict = {}\n",
    "\n",
    "for pid_count, pid in enumerate(novel_pids):\n",
    "    print(f\"PID {pid}, {pid_count}/{len(novel_pids)}\")\n",
    "    novel_pid_res_dict[pid] = {}\n",
    "\n",
    "    # Create the testloader by segmenting out this specific pid\n",
    "    # Filter based on participant_id\n",
    "    indices = [i for i, datasplit_pid in enumerate(novel_participant_ft_data['participant_ids']) if datasplit_pid == pid]\n",
    "    ############## Novel Participant Finetuning Dataset ##############\n",
    "    ft_dataset = GestureDataset([novel_participant_ft_data['feature'][i] for i in indices], [novel_participant_ft_data['labels'][i] for i in indices])\n",
    "    ft_loader = DataLoader(ft_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "    ############## Novel Participant Intra Testing Dataset ##############\n",
    "    indices = [i for i, datasplit_pid in enumerate(novel_participant_test_data['participant_ids']) if datasplit_pid == pid]\n",
    "    intra_test_dataset = GestureDataset([novel_participant_test_data['feature'][i] for i in indices], [novel_participant_test_data['labels'][i] for i in indices])\n",
    "    intra_test_loader = DataLoader(intra_test_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "    ############## Novel Participant Cross Testing Dataset ##############\n",
    "    indices = [i for i, datasplit_pid in enumerate(novel_participant_test_data['participant_ids']) if datasplit_pid != pid]\n",
    "    cross_test_dataset = GestureDataset([novel_participant_test_data['feature'][i] for i in indices], [novel_participant_test_data['labels'][i] for i in indices])\n",
    "    cross_test_loader = DataLoader(intra_test_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "    ############## One Trial Cluster Assignment Dataset ##############\n",
    "    indices = [i for i, datasplit_pid in enumerate(one_trial_data_splits['participant_ids']) if datasplit_pid == pid]\n",
    "    clust_asgn_dataset = GestureDataset([one_trial_data_splits['feature'][i] for i in indices], [one_trial_data_splits['labels'][i] for i in indices])\n",
    "    clust_asgn_loader = DataLoader(clust_asgn_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "\n",
    "    # 1) Train a local CNN model\n",
    "    local_model = CNNModel_3layer(config, input_dim=80, num_classes=10)\n",
    "\n",
    "    local_results = main_training_pipeline(data_splits=None, train_intra_cross_loaders=[ft_loader, intra_test_loader, cross_test_loader],\n",
    "                        all_participants=train_pids, test_participants=novel_pids, model_type=local_model,  \n",
    "                        num_epochs=num_local_training_epochs, config=config)\n",
    "    # This is kind of repeated but whatever\n",
    "    local_clus_res = evaluate_model(local_model, intra_test_loader)\n",
    "    novel_pid_res_dict[pid][\"local_acc\"] = local_clus_res[\"accuracy\"]\n",
    "\n",
    "    # 2) Have the pretrained CNN model from the best cluster do inference\n",
    "    #   - Have all cluster models do inference and compare assign to whichever cluster gives best results\n",
    "    #pretrained_generic_CNN_model\n",
    "\n",
    "    # Apply all the cluster models at the chosen iteration on the given participant data\n",
    "    ## Record that cluster's performance (all cluster's performances?... Ideally)\n",
    "\n",
    "    clus_model_res_dict = {}\n",
    "    for clus_id in cluster_lst:\n",
    "        clus_model = nested_clus_model_dict['Iter18'][clus_id]\n",
    "        clus_res = evaluate_model(clus_model, clust_asgn_loader) \n",
    "        clus_acc = clus_res[\"accuracy\"]\n",
    "        clus_model_res_dict[clus_id] = clus_acc\n",
    "        \n",
    "    # Assign participant to highest scoring cluster\n",
    "    # Find the key with the highest accuracy\n",
    "    max_key = max(clus_model_res_dict, key=clus_model_res_dict.get)\n",
    "    max_value = clus_model_res_dict[max_key]\n",
    "    print(f\"The highest accuracy is {max_value} and it is associated with the key {max_key}.\")\n",
    "    print(\"Full cluster assignment results dict:\")\n",
    "    print(clus_model_res_dict)\n",
    "\n",
    "    original_cluster_model = nested_clus_model_dict['Iter18'][max_key]\n",
    "\n",
    "    # Have the pretrained CNN model from the best cluster do inference\n",
    "    pretrained_clus_res = evaluate_model(original_cluster_model, intra_test_loader)\n",
    "    novel_pid_res_dict[pid][\"pretrained_acc\"] = pretrained_clus_res[\"accuracy\"]\n",
    "\n",
    "    # 3) FT the above model (or all??) pretrained CNN model on the participant\n",
    "    ft_model, original_cluster_model, train_loss_log, test_loss_log = fine_tune_model(\n",
    "        original_cluster_model, ft_loader, intra_test_loader, num_epochs=num_ft_epochs, lr=ft_lr)\n",
    "    ft_clus_res = evaluate_model(ft_model, intra_test_loader)\n",
    "    novel_pid_res_dict[pid][\"ft_acc\"] = ft_clus_res[\"accuracy\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dcba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_acc_data = [] \n",
    "pretrained_acc_data = [] \n",
    "ft_acc_data = [] \n",
    "# Collecting data from the dictionary \n",
    "for pid in novel_pid_res_dict: \n",
    "    local_acc_data.extend(novel_pid_res_dict[pid]['local_acc']) \n",
    "    pretrained_acc_data.extend(novel_pid_res_dict[pid]['pretrained_acc']) \n",
    "    ft_acc_data.extend(novel_pid_res_dict[pid]['ft_acc']) \n",
    "# Plotting box plots \n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5)) \n",
    "axes[0].boxplot(local_acc_data) \n",
    "axes[0].set_title('Local Accuracy') \n",
    "axes[0].set_ylabel('Accuracy') \n",
    "axes[1].boxplot(pretrained_acc_data) \n",
    "axes[1].set_title('Pretrained Accuracy') \n",
    "axes[1].set_ylabel('Accuracy') \n",
    "axes[2].boxplot(ft_acc_data) \n",
    "axes[2].set_title('Fine-Tuned Accuracy') \n",
    "axes[2].set_ylabel('Accuracy') \n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397ce5ef",
   "metadata": {},
   "source": [
    "# Logging / Reporting / Plotting\n",
    "> Really ought to log results somehow..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d95505",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
