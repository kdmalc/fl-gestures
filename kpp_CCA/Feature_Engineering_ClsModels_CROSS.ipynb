{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a62336d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5d47af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e81fcec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11/5: cca is unsup. for expert: fit in X_expert, X_other instead of y\n",
    "\n",
    "\n",
    "\n",
    "#10/29. do PCA instead of CCA without expert user. should take same inputs. figure out what structure needed to effectively run PCA\n",
    "##### try LDA or SVC instead of KNN \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#10/22\n",
    "#do fft on data prior to working with it\n",
    "#fft: time to freq\n",
    "#ifft: freq to time\n",
    "#where they have EMG, it should be each gesture indiv. pull in the data as the dataframe with each column\n",
    "#look at kai's github for breaking down pickle into gestures\n",
    "\n",
    "#check the directory structure of momona's code\n",
    "\n",
    "#time data going in the moments and time converted to freq should have the same moments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e84bfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Participant Gesture_ID Gesture_Num      EMG1      EMG2      EMG3  \\\n",
      "0            P102  gesture-1           1  0.000002  0.000001  0.000001   \n",
      "1            P102  gesture-1           1  0.000002  0.000002  0.000001   \n",
      "2            P102  gesture-1           1  0.000002  0.000002  0.000002   \n",
      "3            P102  gesture-1           1  0.000002  0.000001  0.000002   \n",
      "4            P102  gesture-1           1  0.000002  0.000001  0.000001   \n",
      "...           ...        ...         ...       ...       ...       ...   \n",
      "99195        P011  gesture-5          10  0.000016  0.000003  0.000003   \n",
      "99196        P011  gesture-5          10  0.000014  0.000003  0.000003   \n",
      "99197        P011  gesture-5          10  0.000014  0.000003  0.000003   \n",
      "99198        P011  gesture-5          10  0.000014  0.000003  0.000002   \n",
      "99199        P011  gesture-5          10  0.000016  0.000003  0.000002   \n",
      "\n",
      "           EMG4      EMG5      EMG6      EMG7      EMG8      EMG9     EMG10  \\\n",
      "0      0.000001  0.000003  0.000003  0.000002  0.000003  0.000003  0.000015   \n",
      "1      0.000001  0.000003  0.000003  0.000002  0.000003  0.000004  0.000027   \n",
      "2      0.000002  0.000003  0.000003  0.000002  0.000003  0.000003  0.000023   \n",
      "3      0.000001  0.000003  0.000003  0.000002  0.000003  0.000003  0.000021   \n",
      "4      0.000001  0.000003  0.000003  0.000002  0.000003  0.000003  0.000018   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "99195  0.000027  0.000011  0.000003  0.000003  0.000057  0.000074  0.000009   \n",
      "99196  0.000030  0.000012  0.000002  0.000002  0.000052  0.000068  0.000002   \n",
      "99197  0.000032  0.000013  0.000002  0.000002  0.000047  0.000056  0.000002   \n",
      "99198  0.000029  0.000011  0.000002  0.000002  0.000045  0.000051  0.000002   \n",
      "99199  0.000033  0.000010  0.000002  0.000002  0.000051  0.000049  0.000001   \n",
      "\n",
      "              EMG11     EMG12     EMG13     EMG14     EMG15     EMG16  \n",
      "0      1.085501e-06  0.000002  0.000002  0.000009  0.000002  0.000002  \n",
      "1      1.077209e-06  0.000002  0.000003  0.000017  0.000001  0.000002  \n",
      "2      9.522238e-07  0.000002  0.000003  0.000016  0.000001  0.000003  \n",
      "3      9.711694e-07  0.000002  0.000003  0.000012  0.000002  0.000003  \n",
      "4      1.078657e-06  0.000002  0.000003  0.000012  0.000002  0.000002  \n",
      "...             ...       ...       ...       ...       ...       ...  \n",
      "99195  3.440191e-06  0.000004  0.000022  0.000002  0.000013  0.000008  \n",
      "99196  3.374612e-06  0.000005  0.000019  0.000002  0.000013  0.000008  \n",
      "99197  4.343276e-06  0.000006  0.000020  0.000002  0.000010  0.000008  \n",
      "99198  5.366922e-06  0.000006  0.000021  0.000002  0.000007  0.000007  \n",
      "99199  6.204895e-06  0.000006  0.000021  0.000002  0.000008  0.000006  \n",
      "\n",
      "[99200 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "stand_path = 'C:\\\\Users\\\\User\\\\Downloads\\\\Momona Data\\\\NEWmetadata_EMG_standardized_allusers.pkl'\n",
    "pers_path = 'C:\\\\Users\\\\User\\\\Downloads\\\\Momona Data\\\\NEWmetadata_EMG_userdef_allusers.pkl'\n",
    "\n",
    "# Open the file in binary mode and load the data\n",
    "with open(pers_path, 'rb') as file:\n",
    "    EMG_pers = pickle.load(file)\n",
    "    \n",
    "with open(stand_path, 'rb') as file:\n",
    "    EMG_stand = pickle.load(file)\n",
    "\n",
    "# Now 'data' contains the deserialized Python object\n",
    "print(EMG_pers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c448f64f",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22a5e61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_order(df_freq):\n",
    "    zero_order_moments_log = []\n",
    "    zero_order_moments_raw = []\n",
    "\n",
    "    for sensor in df_freq.columns:\n",
    "        # Extract the frequency domain data for the sensor (column of the dataframe)\n",
    "        time_data = df_freq[sensor].values\n",
    "        \n",
    "        # Step 1: Square the signal (power) at each frequency\n",
    "        signal_squared = np.abs(time_data) ** 2\n",
    "        \n",
    "        # Step 2: Integrate (sum) the squared values to get the total power\n",
    "        total_power = np.sum(signal_squared)\n",
    "        \n",
    "        # Step 3: Take the logarithm of the total power\n",
    "        log_total_power = np.log(total_power)\n",
    "        \n",
    "        # Store the result in the dictionary\n",
    "        zero_order_moments_log.append(log_total_power)\n",
    "        zero_order_moments_raw.append(total_power)\n",
    "        \n",
    "    return zero_order_moments_log, zero_order_moments_raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "873dc3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_order(df_freq, zero_order_raw):\n",
    "    # Initialize lists to store the results for each sensor\n",
    "    first_order_moments_log = []\n",
    "    first_order_moments_raw = []\n",
    "    \n",
    "    for i,sensor in enumerate(df_freq.columns):\n",
    "        # Extract the frequency domain data for the sensor (column of the dataframe)\n",
    "        time_data = df_freq[sensor].values\n",
    "        \n",
    "        # Step 1: Take first derivative\n",
    "        first_deriv = np.gradient(time_data)\n",
    "        \n",
    "        # Step 2: Square the signal (power) at each frequency of the first deriv\n",
    "        signal_squared = np.abs(first_deriv) ** 2\n",
    "        \n",
    "        # Step 3: Integrate (sum) the squared values to get the total power\n",
    "        total_power = np.sum(signal_squared)\n",
    "        \n",
    "        # Step 4: Take the logarithm of the total power\n",
    "        log_total_power = np.log(total_power / (zero_order_raw[i]**2))\n",
    "        \n",
    "        # Store the results in the lists\n",
    "        first_order_moments_log.append(log_total_power)\n",
    "        first_order_moments_raw.append(total_power)\n",
    "\n",
    "    # Convert lists to numpy arrays for consistency\n",
    "    first_order_moments_log = np.array(first_order_moments_log)\n",
    "    first_order_moments_raw = np.array(first_order_moments_raw)\n",
    "    \n",
    "    return first_order_moments_log, first_order_moments_raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9b315a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_order(df_freq, zero_order_raw):\n",
    "    second_order_log = []\n",
    "    second_order_raw = []\n",
    "\n",
    "    for i, sensor in enumerate(df_freq.columns):\n",
    "        # Extract the time domain data for the sensor (column of the dataframe)\n",
    "        time_data = df_freq[sensor].values\n",
    "        \n",
    "        # Step 1: Take first derivative\n",
    "        first_deriv = np.gradient(time_data)\n",
    "        \n",
    "        #Step 2: take second derivative\n",
    "        second_deriv = np.gradient(first_deriv)\n",
    "        \n",
    "        # Step 3: Square the signal (power) at each frequency of the first deriv\n",
    "        signal_squared = np.abs(second_deriv) ** 2\n",
    "        \n",
    "        # Step 4: Integrate (sum) the squared values to get the total power\n",
    "        total_power = np.sum(signal_squared)\n",
    "        \n",
    "        # Step 4: Take the logarithm of the total power\n",
    "        log_total_power = np.log(total_power/(zero_order_raw[i]**4))\n",
    "        \n",
    "        # Store the result in the dictionary\n",
    "        second_order_log.append(log_total_power)\n",
    "        second_order_raw.append(total_power)\n",
    "\n",
    "    \n",
    "    return second_order_log, second_order_raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aed260c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#working version of third_order that has precautions so no neg values inside log\n",
    "def third_order(second_order_raw, first_order_raw, zero_order_raw):\n",
    "    second_order_raw = np.array(second_order_raw)\n",
    "    first_order_raw = np.array(first_order_raw)\n",
    "    zero_order_raw = np.array(zero_order_raw)\n",
    "    \n",
    "    # Step 1: Compute the square roots (ensure no negative values before sqrt)\n",
    "    sqrt_first_diff = np.sqrt(np.maximum(zero_order_raw - first_order_raw, 1e-10))  # Handle small or negative values\n",
    "    sqrt_second_diff = np.sqrt(np.maximum(zero_order_raw - second_order_raw, 1e-10))  # Handle small or negative values\n",
    "    \n",
    "    # Step 2: Perform the dot product (ensure no division by zero by adding a small constant)\n",
    "    dot_product = np.dot(sqrt_first_diff, sqrt_second_diff)\n",
    "    dot_product = max(dot_product, 1e-10)  # Avoid division by zero or extremely small numbers\n",
    "    \n",
    "    # Step 3: Compute the sparseness ratio (ensure the result is positive)\n",
    "    sparseness = zero_order_raw / dot_product\n",
    "    \n",
    "    # Step 4: Logarithm of the sparseness (ensure no negative or zero values inside the log)\n",
    "    # We use np.maximum to ensure all values are at least 1e-10 to avoid taking log of non-positive values.\n",
    "    safe_sparseness = np.maximum(sparseness, 1e-10)\n",
    "    \n",
    "    #print(\"Safe sparseness:\", safe_sparseness)\n",
    "    \n",
    "    # Step 5: Apply the logarithm for third-order moments\n",
    "    third_order_moments_log = np.log(safe_sparseness)\n",
    "    \n",
    "    return third_order_moments_log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cdeeb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourth_order(df_freq, zero_order_raw, first_order_raw, second_order_raw):\n",
    "    # Initialize a list to store the fourth-order moments log for each sensor\n",
    "    fourth_order_moments_logs = []\n",
    "    \n",
    "    for i,sensor in enumerate(df_freq.columns):\n",
    "        # Extract the time domain data for the sensor (column of the dataframe)\n",
    "        time_data = df_freq[sensor].values\n",
    "        \n",
    "        # Step 1: Take first derivative\n",
    "        first_deriv = np.gradient(time_data)\n",
    "        \n",
    "        # Step 2: Absolute value of the signal (power) at each frequency of the first derivative\n",
    "        signal_abs = np.abs(first_deriv)\n",
    "        \n",
    "        # Step 3: Integrate (sum) the absolute values to get the total power\n",
    "        total_power = np.sum(signal_abs)\n",
    "        \n",
    "        # Step 4: Compute the fourth-order moments log for this sensor\n",
    "        moment_log = np.log(np.sqrt((first_order_raw[i]**2) / \n",
    "                           (zero_order_raw[i] * second_order_raw[i])) / total_power)\n",
    "        \n",
    "        # Store the result in the list\n",
    "        fourth_order_moments_logs.append(moment_log)\n",
    "    \n",
    "    # Convert list to numpy array for consistency\n",
    "    fourth_order_moments_logs = np.array(fourth_order_moments_logs)\n",
    "    \n",
    "    return fourth_order_moments_logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b08c98f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_vectors(group):\n",
    "    result_vector = []\n",
    "    #can only run features on EMG columns\n",
    "    emg_columns = [col for col in group.columns if col.startswith('EMG')]\n",
    "    \n",
    "    for emg_col in emg_columns:\n",
    "        data = group[[emg_col]] #run on EMG columns. convert to df with single column to run with all the features\n",
    "        \n",
    "        #zero-order\n",
    "        zero_order_log, zero_order_raw = zero_order(data)\n",
    "        result_vector.append(zero_order_log)\n",
    "        \n",
    "        #first-order\n",
    "        first_order_log, first_order_raw = first_order(data, zero_order_raw)\n",
    "        result_vector.append(first_order_log)\n",
    "        \n",
    "        #second-order\n",
    "        second_order_log, second_order_raw = second_order(data, zero_order_raw)\n",
    "        result_vector.append(second_order_log)\n",
    "        \n",
    "        #third-order\n",
    "        third_order_log = third_order(second_order_raw, first_order_raw, zero_order_raw)\n",
    "        result_vector.append(third_order_log)\n",
    "        \n",
    "        #fourth-order\n",
    "        fourth_order_log = fourth_order(data, zero_order_raw, first_order_raw, second_order_raw)\n",
    "        result_vector.append(fourth_order_log)\n",
    "        \n",
    "    return pd.DataFrame({\n",
    "        'Participant': [group['Participant'].iloc[0]],\n",
    "        'Gesture_ID': [group['Gesture_ID'].iloc[0]],\n",
    "        'Gesture_Num': [group['Gesture_Num'].iloc[0]],\n",
    "        'feature': [np.array(result_vector)]\n",
    "    })\n",
    "result = EMG_stand.groupby(['Participant', 'Gesture_ID', 'Gesture_Num']).apply(create_feature_vectors)\n",
    "\n",
    "#output is df with particpant, gesture_ID, gesture_num and feature (holds 80 len vector)\n",
    "result = result.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a9784e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "userdef = EMG_pers.groupby(['Participant', 'Gesture_ID', 'Gesture_Num']).apply(create_feature_vectors)\n",
    "\n",
    "#output is df with particpant, gesture_ID, gesture_num and feature (holds 80 len vector)\n",
    "userdef = userdef.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "635ee7e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "#confirmed that all vectors are the same length (80)\n",
    "for i in range(40):\n",
    "    print(len(userdef['feature'].loc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9f5bcea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant</th>\n",
       "      <th>Gesture_ID</th>\n",
       "      <th>Gesture_Num</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P004</td>\n",
       "      <td>gesture-1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-23.26249377989712], [18.016590958660785], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P004</td>\n",
       "      <td>gesture-1</td>\n",
       "      <td>10</td>\n",
       "      <td>[[-23.24165786128314], [17.846433634527166], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P004</td>\n",
       "      <td>gesture-1</td>\n",
       "      <td>2</td>\n",
       "      <td>[[-23.23998758618434], [16.66865598878668], [6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P004</td>\n",
       "      <td>gesture-1</td>\n",
       "      <td>3</td>\n",
       "      <td>[[-23.207208838399126], [17.61917815123758], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P004</td>\n",
       "      <td>gesture-1</td>\n",
       "      <td>4</td>\n",
       "      <td>[[-23.284384985499166], [17.674295511346255], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>P132</td>\n",
       "      <td>gesture-5</td>\n",
       "      <td>5</td>\n",
       "      <td>[[-17.55741253047571], [15.749595268750634], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>P132</td>\n",
       "      <td>gesture-5</td>\n",
       "      <td>6</td>\n",
       "      <td>[[-17.040444837807332], [15.687440605336647], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>P132</td>\n",
       "      <td>gesture-5</td>\n",
       "      <td>7</td>\n",
       "      <td>[[-17.29138625623744], [15.337172953351514], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548</th>\n",
       "      <td>P132</td>\n",
       "      <td>gesture-5</td>\n",
       "      <td>8</td>\n",
       "      <td>[[-17.134138008109343], [15.183812380351172], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>P132</td>\n",
       "      <td>gesture-5</td>\n",
       "      <td>9</td>\n",
       "      <td>[[-16.83216091507738], [14.802823107846402], [...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1550 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Participant Gesture_ID Gesture_Num  \\\n",
       "0           P004  gesture-1           1   \n",
       "1           P004  gesture-1          10   \n",
       "2           P004  gesture-1           2   \n",
       "3           P004  gesture-1           3   \n",
       "4           P004  gesture-1           4   \n",
       "...          ...        ...         ...   \n",
       "1545        P132  gesture-5           5   \n",
       "1546        P132  gesture-5           6   \n",
       "1547        P132  gesture-5           7   \n",
       "1548        P132  gesture-5           8   \n",
       "1549        P132  gesture-5           9   \n",
       "\n",
       "                                                feature  \n",
       "0     [[-23.26249377989712], [18.016590958660785], [...  \n",
       "1     [[-23.24165786128314], [17.846433634527166], [...  \n",
       "2     [[-23.23998758618434], [16.66865598878668], [6...  \n",
       "3     [[-23.207208838399126], [17.61917815123758], [...  \n",
       "4     [[-23.284384985499166], [17.674295511346255], ...  \n",
       "...                                                 ...  \n",
       "1545  [[-17.55741253047571], [15.749595268750634], [...  \n",
       "1546  [[-17.040444837807332], [15.687440605336647], ...  \n",
       "1547  [[-17.29138625623744], [15.337172953351514], [...  \n",
       "1548  [[-17.134138008109343], [15.183812380351172], ...  \n",
       "1549  [[-16.83216091507738], [14.802823107846402], [...  \n",
       "\n",
       "[1550 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userdef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c4d3ae",
   "metadata": {},
   "source": [
    "# CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0ec8550",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert Gesture_ID to numerical with new Gesture_Encoded column\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "result['Gesture_Encoded'] = label_encoder.fit_transform(result['Gesture_ID'])\n",
    "userdef['Gesture_Encoded'] = label_encoder.fit_transform(userdef['Gesture_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e7dfcf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P004    50\n",
       "P112    50\n",
       "P128    50\n",
       "P127    50\n",
       "P126    50\n",
       "P125    50\n",
       "P124    50\n",
       "P123    50\n",
       "P122    50\n",
       "P121    50\n",
       "P119    50\n",
       "P118    50\n",
       "P116    50\n",
       "P115    50\n",
       "P114    50\n",
       "P111    50\n",
       "P005    50\n",
       "P110    50\n",
       "P109    50\n",
       "P108    50\n",
       "P107    50\n",
       "P106    50\n",
       "P105    50\n",
       "P104    50\n",
       "P103    50\n",
       "P102    50\n",
       "P011    50\n",
       "P010    50\n",
       "P008    50\n",
       "P006    50\n",
       "P132    50\n",
       "Name: Participant, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count number of rows per PID\n",
    "result['Participant'].value_counts()\n",
    "userdef['Participant'].value_counts() #yay! all user-def are same length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82caad1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant</th>\n",
       "      <th>Gesture_ID</th>\n",
       "      <th>Gesture_Num</th>\n",
       "      <th>feature</th>\n",
       "      <th>Gesture_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>P104</td>\n",
       "      <td>air-tap</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-19.931494507190266], [14.43852161455601], [...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>P104</td>\n",
       "      <td>air-tap</td>\n",
       "      <td>10</td>\n",
       "      <td>[[-20.473594370607508], [15.84688054857665], [...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>P104</td>\n",
       "      <td>air-tap</td>\n",
       "      <td>2</td>\n",
       "      <td>[[-19.639110285656656], [14.918420781285667], ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>P104</td>\n",
       "      <td>air-tap</td>\n",
       "      <td>3</td>\n",
       "      <td>[[-20.040428885228497], [15.268214541976569], ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>P104</td>\n",
       "      <td>air-tap</td>\n",
       "      <td>4</td>\n",
       "      <td>[[-20.05366602050795], [15.511636569909998], [...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>P132</td>\n",
       "      <td>two-handed-tap</td>\n",
       "      <td>5</td>\n",
       "      <td>[[-19.07993955504957], [17.24214204325393], [5...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>P132</td>\n",
       "      <td>two-handed-tap</td>\n",
       "      <td>6</td>\n",
       "      <td>[[-18.73670013388571], [15.592195296620298], [...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>P132</td>\n",
       "      <td>two-handed-tap</td>\n",
       "      <td>7</td>\n",
       "      <td>[[-19.075612774367713], [16.198239062623255], ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>P132</td>\n",
       "      <td>two-handed-tap</td>\n",
       "      <td>8</td>\n",
       "      <td>[[-19.552360489246766], [17.701475682262988], ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>P132</td>\n",
       "      <td>two-handed-tap</td>\n",
       "      <td>9</td>\n",
       "      <td>[[-19.215584388871292], [15.30413921190205], [...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Participant      Gesture_ID Gesture_Num  \\\n",
       "600         P104         air-tap           1   \n",
       "601         P104         air-tap          10   \n",
       "602         P104         air-tap           2   \n",
       "603         P104         air-tap           3   \n",
       "604         P104         air-tap           4   \n",
       "...          ...             ...         ...   \n",
       "1110        P132  two-handed-tap           5   \n",
       "1111        P132  two-handed-tap           6   \n",
       "1112        P132  two-handed-tap           7   \n",
       "1113        P132  two-handed-tap           8   \n",
       "1114        P132  two-handed-tap           9   \n",
       "\n",
       "                                                feature  Gesture_Encoded  \n",
       "600   [[-19.931494507190266], [14.43852161455601], [...                0  \n",
       "601   [[-20.473594370607508], [15.84688054857665], [...                0  \n",
       "602   [[-19.639110285656656], [14.918420781285667], ...                0  \n",
       "603   [[-20.040428885228497], [15.268214541976569], ...                0  \n",
       "604   [[-20.05366602050795], [15.511636569909998], [...                0  \n",
       "...                                                 ...              ...  \n",
       "1110  [[-19.07993955504957], [17.24214204325393], [5...                9  \n",
       "1111  [[-18.73670013388571], [15.592195296620298], [...                9  \n",
       "1112  [[-19.075612774367713], [16.198239062623255], ...                9  \n",
       "1113  [[-19.552360489246766], [17.701475682262988], ...                9  \n",
       "1114  [[-19.215584388871292], [15.30413921190205], [...                9  \n",
       "\n",
       "[500 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only keep participants with 50 rows (disabled and did all gestures)\n",
    "participant_counts = result['Participant'].value_counts()\n",
    "\n",
    "# Filter participants who have exactly 50 rows\n",
    "with_disability = result[result['Participant'].isin(participant_counts[participant_counts == 50].index)].copy()\n",
    "\n",
    "# Display the filtered dataset\n",
    "with_disability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5438cbca",
   "metadata": {},
   "source": [
    "CCA functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4895a623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hold out one participant as the expert\n",
    "def hold_out_expert(data, participant_column):\n",
    "    participant_ids = data[participant_column].unique()\n",
    "    expert_user = np.random.choice(participant_ids)  # Randomly select one participant as expert\n",
    "    data_expert = data[data[participant_column] == expert_user]  # Expert data\n",
    "    data_remaining = data[data[participant_column] != expert_user]  # Remaining data\n",
    "    return data_expert, data_remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ba2d39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split for remaining data\n",
    "def split_train_test(data, participant_column, test_size=0.2):\n",
    "    participant_ids = data[participant_column].unique()\n",
    "    train_ids, test_ids = train_test_split(participant_ids, test_size=test_size, random_state=42)\n",
    "    \n",
    "    train_data = data[data[participant_column].isin(train_ids)]\n",
    "    test_data = data[data[participant_column].isin(test_ids)]\n",
    "    \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2f24a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_features(feature_column):\n",
    "    # Convert a column of lists of lists into a 2D NumPy array\n",
    "    return np.array([np.array(item).flatten() for item in feature_column])\n",
    "#X_expert = flatten_features(expert_data['feature']) #now  a 2D array with \n",
    "#X_other = flatten_features(remaining_data['feature'])\n",
    "\n",
    "#print(X_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae078f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inside k_fold function\n",
    "# Apply CCA btwn expert and train/test\n",
    "def apply_cca_between_expert_and_others(expert_data, other_data, target_column, n_components=2):\n",
    "    # Separate features (X) and target (y)\n",
    "    \n",
    "    #after flattening to 2D \n",
    "    X_expert = flatten_features(expert_data['feature'])\n",
    "    X_other = flatten_features(other_data['feature'])\n",
    "\n",
    "    y_expert = expert_data[target_column]\n",
    "    y_other = other_data[target_column]\n",
    "    \n",
    "    # Apply CCA between expert and other participant\n",
    "    cca = CCA(n_components=n_components)\n",
    "    #cca.fit(X_expert, y_expert)\n",
    "    #print(X_expert.shape)\n",
    "    #print(X_other.shape)\n",
    "    cca.fit(X_expert, X_other) #might not run bcuz diff shapes\n",
    "    #need to figure out how to pass in X_others. if not clear from paper, google cca github and try to find expert user and others\n",
    "    X_other_cca = cca.transform(X_other)\n",
    "    \n",
    "    return X_other_cca, y_other#, X_expert, X_other#, X_other, X_expert, y_expert            think we're good to leave this out?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "920c2a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inside k_fold function\n",
    "# Run KNN -- used inside cca but can also be used outside\n",
    "def run_knn(X_train, y_train, X_test, y_test, n_neighbors=5):\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    return accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c48ebe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement k-fold cross-validation and refer to each of the other functions to run CCA between expert user and training and expert user and testing\n",
    "def k_fold_cross_validation(data, expert_data, participant_column, target_column, k=5, n_neighbors=5, n_components=2):\n",
    "\n",
    "    group_kf = GroupKFold(n_splits=k)\n",
    "    accuracies = []\n",
    "    \n",
    "    #80/20 train test split. 4 folds in train and 1 in test\n",
    "    for train_index, test_index in group_kf.split(data, groups=data[participant_column]):\n",
    "        # Split based on participant IDs\n",
    "        train_ids = data[participant_column].iloc[train_index].unique()\n",
    "        test_ids = data[participant_column].iloc[test_index].unique()\n",
    "        \n",
    "        train_data = data[data[participant_column].isin(train_ids)]\n",
    "        test_data = data[data[participant_column].isin(test_ids)]\n",
    "        \n",
    "        #print(\"total data:\", data.shape)\n",
    "        #print(\"train\", train_data[participant_column].unique())\n",
    "        #print(\"Test\", test_data[participant_column].unique())\n",
    "        # CCA between expert and training users\n",
    "        X_train_cca = []\n",
    "        y_train = []\n",
    "        for pid in train_ids:\n",
    "            pid_data = train_data[train_data[participant_column] == pid]\n",
    "            #print(\"participant id\", pid)\n",
    "            #print(\"expert data\", expert_data.shape)\n",
    "            #print(\"participant data\", pid_data.shape)\n",
    "            X_pid_cca, y_pid = apply_cca_between_expert_and_others(expert_data, pid_data, target_column, n_components)\n",
    "            X_train_cca.append(X_pid_cca)\n",
    "            y_train.append(y_pid)\n",
    "        \n",
    "        # Combine all CCA-transformed training data\n",
    "        X_train_cca = np.vstack(X_train_cca)\n",
    "        y_train = np.concatenate(y_train)\n",
    "        \n",
    "        # CCA between expert and testing users\n",
    "        X_test_cca = []\n",
    "        y_test = []\n",
    "        for pid in test_ids:\n",
    "            pid_data = test_data[test_data[participant_column] == pid]\n",
    "            #change to X_expert, X_other for output     X_pid_cca, y_pid = apply_cca_between_expert_and_others(expert_data, pid_data, target_column, n_components)\n",
    "            X_test_cca.append(X_pid_cca)\n",
    "            y_test.append(y_pid)\n",
    "        \n",
    "        # Combine all CCA-transformed testing data\n",
    "        X_test_cca = np.vstack(X_test_cca)\n",
    "        y_test = np.concatenate(y_test)\n",
    "        \n",
    "        # Run KNN on CCA-transformed feature sets\n",
    "        accuracy = run_knn(X_train_cca, y_train, X_test_cca, y_test, n_neighbors)\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4060da5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant</th>\n",
       "      <th>Gesture_ID</th>\n",
       "      <th>Gesture_Num</th>\n",
       "      <th>feature</th>\n",
       "      <th>Gesture_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>P132</td>\n",
       "      <td>air-tap</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-19.16652871842587], [16.724676482435193], [...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>P132</td>\n",
       "      <td>air-tap</td>\n",
       "      <td>10</td>\n",
       "      <td>[[-18.18052481900217], [16.294732335445037], [...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>P132</td>\n",
       "      <td>air-tap</td>\n",
       "      <td>2</td>\n",
       "      <td>[[-19.33160301184248], [17.348993130369358], [...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>P132</td>\n",
       "      <td>air-tap</td>\n",
       "      <td>3</td>\n",
       "      <td>[[-19.11583968101696], [17.28483517202384], [5...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>P132</td>\n",
       "      <td>air-tap</td>\n",
       "      <td>4</td>\n",
       "      <td>[[-18.406120681413714], [16.16664693085155], [...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Participant Gesture_ID Gesture_Num  \\\n",
       "1065        P132    air-tap           1   \n",
       "1066        P132    air-tap          10   \n",
       "1067        P132    air-tap           2   \n",
       "1068        P132    air-tap           3   \n",
       "1069        P132    air-tap           4   \n",
       "\n",
       "                                                feature  Gesture_Encoded  \n",
       "1065  [[-19.16652871842587], [16.724676482435193], [...                0  \n",
       "1066  [[-18.18052481900217], [16.294732335445037], [...                0  \n",
       "1067  [[-19.33160301184248], [17.348993130369358], [...                0  \n",
       "1068  [[-19.11583968101696], [17.28483517202384], [5...                0  \n",
       "1069  [[-18.406120681413714], [16.16664693085155], [...                0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_data, remaining_data = hold_out_expert(with_disability, 'Participant')\n",
    "expert_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "587f8411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data: (450, 5)\n",
      "train ['P104' 'P111' 'P114' 'P119' 'P123' 'P124' 'P126']\n",
      "Test ['P116' 'P132']\n",
      "total data: (450, 5)\n",
      "train ['P104' 'P111' 'P116' 'P119' 'P123' 'P124' 'P132']\n",
      "Test ['P114' 'P126']\n",
      "total data: (450, 5)\n",
      "train ['P104' 'P114' 'P116' 'P119' 'P123' 'P126' 'P132']\n",
      "Test ['P111' 'P124']\n",
      "total data: (450, 5)\n",
      "train ['P111' 'P114' 'P116' 'P119' 'P124' 'P126' 'P132']\n",
      "Test ['P104' 'P123']\n",
      "total data: (450, 5)\n",
      "train ['P104' 'P111' 'P114' 'P116' 'P123' 'P124' 'P126' 'P132']\n",
      "Test ['P119']\n"
     ]
    }
   ],
   "source": [
    "expert_data, remaining_data = hold_out_expert(with_disability, 'Participant')\n",
    "cca_knn_accuracy=k_fold_cross_validation(remaining_data, expert_data, 'Participant', 'Gesture_Encoded', k=5, n_neighbors=5, n_components=2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f11ed680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized Mean accuracies per participant: {'P104': 0.6400000000000001, 'P124': 0.6399999999999999, 'P105': 0.58, 'P123': 0.4600000000000001, 'P126': 0.8, 'P114': 0.7, 'P111': 0.7799999999999999, 'P119': 0.66, 'P116': 0.5, 'P132': 0.82}\n",
      "User-Def Mean accuracies per participant: {'P109': 0.58, 'P108': 0.62, 'P127': 0.6, 'P114': 0.5, 'P132': 0.56, 'P106': 0.6799999999999999, 'P119': 0.5, 'P123': 0.76, 'P005': 0.62, 'P116': 0.48, 'P004': 0.54, 'P118': 0.54, 'P006': 0.54, 'P115': 0.48, 'P103': 0.42, 'P112': 0.4000000000000001, 'P125': 0.6, 'P122': 0.72, 'P111': 0.6, 'P010': 0.56, 'P008': 0.5, 'P121': 0.5, 'P110': 0.6, 'P104': 0.66, 'P107': 0.56, 'P126': 0.54, 'P011': 0.48, 'P102': 0.58}\n"
     ]
    }
   ],
   "source": [
    "#11/11 output with k-fold and averaging for 100 runs\n",
    "\n",
    "#train_data, test_data = split_train_test(with_disability, 'Participant', test_size=0.2)\n",
    "#In CCA, the number of components must be less than or equal to the number of features in either dataset or the number of samples minus one, whichever is smaller.\n",
    "#so changed n_components to 1\n",
    "standard_rep = {}\n",
    "for i in range(100):\n",
    "    expert_data, remaining_data = hold_out_expert(with_disability, 'Participant')\n",
    "    cca_knn_accuracy=k_fold_cross_validation(remaining_data, expert_data, 'Participant', 'Gesture_Encoded', k=5, n_neighbors=5, n_components=2)\n",
    "    \n",
    "    #get mean accuracy for each expert_id\n",
    "    participants = expert_data['Participant'].unique()\n",
    "    for participant, accuracy in zip(participants, cca_knn_accuracy):\n",
    "        if participant not in standard_rep:\n",
    "            standard_rep[participant] = []\n",
    "        standard_rep[participant].append(accuracy)\n",
    "\n",
    "\n",
    "# Calculate mean accuracy per participant\n",
    "mean_accuracies_per_participant = {participant: np.mean(accuracies) for participant, accuracies in standard_rep.items()}\n",
    "\n",
    "print(\"Standardized Mean accuracies per participant:\", mean_accuracies_per_participant)\n",
    "\n",
    "\n",
    "#train_data, test_data = split_train_test(userdef, 'Participant', test_size=0.2)\n",
    "#In CCA, the number of components must be less than or equal to the number of features in either dataset or the number of samples minus one, whichever is smaller.\n",
    "#so changed n_components to 1\n",
    "userdef_rep = {}\n",
    "for i in range(100):\n",
    "    expert_data, remaining_data = hold_out_expert(userdef, 'Participant')\n",
    "    cca_knn_accuracy=k_fold_cross_validation(remaining_data, expert_data, 'Participant', 'Gesture_Encoded', k=5, n_neighbors=5, n_components=2)\n",
    "    \n",
    "    #get mean accuracy for each expert_id\n",
    "    participants = expert_data['Participant'].unique()\n",
    "    for participant, accuracy in zip(participants, cca_knn_accuracy):\n",
    "        if participant not in userdef_rep:\n",
    "            userdef_rep[participant] = []\n",
    "        userdef_rep[participant].append(accuracy)\n",
    "\n",
    "# Calculate mean accuracy per participant\n",
    "mean_accuracies_per_participant = {participant: np.mean(accuracies) for participant, accuracies in userdef_rep.items()}\n",
    "\n",
    "print(\"User-Def Mean accuracies per participant:\", mean_accuracies_per_participant)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "090b738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11/11 without k-fold\n",
    "def apply_cca_and_knn(data, expert_data, participant_column, target_column, test_size=0.2, n_neighbors=5, n_components=2):\n",
    "    # Split the remaining data into train and test sets using the provided function\n",
    "    train_data, test_data = split_train_test(data, participant_column, test_size=test_size)\n",
    "    #print(\"train data shape\", train_data.shape)\n",
    "    #print(\"test data shape\", test_data.shape)\n",
    "\n",
    "    \n",
    "    # Apply CCA individually for each training user with the expert\n",
    "    X_train_cca = []\n",
    "    y_train = []\n",
    "    for pid in train_data[participant_column].unique():\n",
    "        pid_data = train_data[train_data[participant_column] == pid]\n",
    "        # Individual CCA model and transformation for each training participant\n",
    "        X_pid_cca, y_pid = apply_cca_between_expert_and_others(expert_data, pid_data, target_column, n_components)\n",
    "        X_train_cca.append(X_pid_cca)\n",
    "        y_train.append(y_pid)\n",
    "    \n",
    "    # Combine all CCA-transformed training data\n",
    "    X_train_cca = np.vstack(X_train_cca)  # Combining individual transformations\n",
    "    y_train = np.concatenate(y_train)\n",
    "    \n",
    "    # Apply CCA individually for each testing user with the expert\n",
    "    X_test_cca = []\n",
    "    y_test = []\n",
    "    for pid in test_data[participant_column].unique():\n",
    "        pid_data = test_data[test_data[participant_column] == pid]\n",
    "        # Individual CCA model and transformation for each testing participant\n",
    "        X_pid_cca, y_pid = apply_cca_between_expert_and_others(expert_data, pid_data, target_column, n_components)\n",
    "        X_test_cca.append(X_pid_cca)\n",
    "        y_test.append(y_pid)\n",
    "    \n",
    "    # Combine all CCA-transformed testing data\n",
    "    X_test_cca = np.vstack(X_test_cca)  # Combining individual transformations\n",
    "    y_test = np.concatenate(y_test)\n",
    "    \n",
    "    # Run KNN on CCA-transformed feature sets\n",
    "    accuracy = run_knn(X_train_cca, y_train, X_test_cca, y_test, n_neighbors)\n",
    "    \n",
    "    return accuracy\n",
    "#expert_data, remaining_data = hold_out_expert(with_disability, 'Participant')\n",
    "#In CCA, the number of components must be less than or equal to the number of features in either dataset or the number of samples minus one, whichever is smaller.\n",
    "#so changed n_components to 1\n",
    "#cca_knn_accuracy=apply_cca_and_knn(remaining_data, expert_data, 'Participant', 'Gesture_Encoded')\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d63279ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " No KNN Standardized Mean accuracies per participant: {'P114': 0.15, 'P123': 0.23, 'P111': 0.11, 'P105': 0.31, 'P119': 0.18, 'P116': 0.15, 'P124': 0.25, 'P132': 0.28, 'P126': 0.17, 'P104': 0.18}\n",
      "No KNN User-Def Mean accuracies per participant: {'P107': 0.15666666666666668, 'P102': 0.18666666666666668, 'P122': 0.22, 'P008': 0.16333333333333333, 'P128': 0.21, 'P121': 0.16, 'P132': 0.17666666666666667, 'P010': 0.19666666666666666, 'P109': 0.12333333333333334, 'P110': 0.21, 'P112': 0.23666666666666666, 'P011': 0.19666666666666666, 'P115': 0.20333333333333334, 'P105': 0.22333333333333333, 'P116': 0.21333333333333335, 'P005': 0.17, 'P123': 0.18666666666666668, 'P006': 0.22666666666666666, 'P127': 0.24, 'P125': 0.17333333333333334, 'P108': 0.21333333333333335, 'P111': 0.24, 'P004': 0.16666666666666666, 'P103': 0.20333333333333334, 'P104': 0.25666666666666665, 'P118': 0.22666666666666666, 'P114': 0.23, 'P124': 0.18333333333333332, 'P106': 0.15333333333333332, 'P119': 0.19666666666666666}\n"
     ]
    }
   ],
   "source": [
    "#running cca with no k-fold and averaging for 100 runs\n",
    "standard_nokfold = {}  # Dictionary to store accuracies per participant\n",
    "\n",
    "for i in range(100):\n",
    "    expert_data, remaining_data = hold_out_expert(with_disability, 'Participant')\n",
    "\n",
    "    \n",
    "    # Apply CCA and KNN, assuming 'apply_cca_and_knn' returns accuracy for this iteration\n",
    "    accuracy = apply_cca_and_knn(remaining_data, expert_data, 'Participant', 'Gesture_Encoded', n_components=1)\n",
    "    \n",
    "    # Add the accuracy to the corresponding participant's list\n",
    "    for pid in expert_data['Participant'].unique():\n",
    "        if pid not in standard_nokfold:\n",
    "            standard_nokfold[pid] = []\n",
    "            standard_nokfold[pid].append(accuracy)\n",
    "\n",
    "# Calculate the mean accuracy for each participant across all iterations\n",
    "mean_accuracies_per_participant = {pid: np.mean(accs) for pid, accs in standard_nokfold.items()}\n",
    "\n",
    "print(\" No KNN Standardized Mean accuracies per participant:\", mean_accuracies_per_participant)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "userdef_nokfold = {}\n",
    "for i in range(100):\n",
    "    expert_data, remaining_data = hold_out_expert(userdef, 'Participant')\n",
    "#train_data, test_data = split_train_test(remaining_data, 'Participant', test_size=0.2)\n",
    "#In CCA, the number of components must be less than or equal to the number of features in either dataset or the number of samples minus one, whichever is smaller.\n",
    "#so changed n_components to 1\n",
    "    accuracy=apply_cca_and_knn(remaining_data, expert_data, 'Participant', 'Gesture_Encoded', n_neighbors=5, n_components=2)\n",
    "    #get mean accuracy for each expert_id\n",
    "    for pid in expert_data['Participant'].unique():\n",
    "        if pid not in userdef_nokfold:\n",
    "            userdef_nokfold[pid] = []\n",
    "            userdef_nokfold[pid].append(accuracy)\n",
    "\n",
    "mean_accuracies_per_participant = {pid: np.mean(accs) for pid, accs in userdef_nokfold.items()}\n",
    "\n",
    "print(\"No KNN User-Def Mean accuracies per participant:\", mean_accuracies_per_participant)\n",
    "\n",
    "#Lower accuracy without k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffa41dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standardized\n",
      "PCA Explained Variance Ratio: [0.30845778 0.13776652 0.10729692 0.06860659 0.05323273 0.03708053\n",
      " 0.03274266 0.02663575 0.02342023 0.02088873]\n",
      "KNN Classification Accuracy: 0.86\n",
      "\n",
      "user-def\n",
      "PCA Explained Variance Ratio: [0.28213244 0.14262123 0.08663335 0.05707593 0.0444905  0.04006048\n",
      " 0.03554242 0.02957199 0.02531161 0.02334016]\n",
      "KNN Classification Accuracy: 0.9225806451612903\n"
     ]
    }
   ],
   "source": [
    "#baseline PCA\n",
    "def run_pca_knn(df, n_components=8, n_neighbors=5, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Perform PCA on the 'feature' column and KNN classification on the transformed data.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): Input DataFrame containing 'feature' and 'Gesture_ID' columns.\n",
    "        n_components (int): Number of PCA components.\n",
    "        n_neighbors (int): Number of neighbors for KNN.\n",
    "        test_size (float): Fraction of data to use as the test set.\n",
    "        random_state (int): Random state for train-test split.\n",
    "\n",
    "    Returns:\n",
    "        explained_variance_ratio (array): Explained variance ratio of PCA components.\n",
    "        accuracy (float): Classification accuracy of KNN on the test set.\n",
    "    \"\"\"\n",
    "    # Convert the 'feature' column from nested lists to a flat list for each entry\n",
    "    df['feature_flat'] = df['feature'].apply(lambda x: np.ravel(x))\n",
    "\n",
    "    # Extract features and labels\n",
    "    X = np.vstack(df['feature_flat'].values)\n",
    "    y = df['Gesture_ID']\n",
    "\n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=test_size)\n",
    "\n",
    "    # Train KNN\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predict and evaluate\n",
    "    y_pred = knn.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return pca.explained_variance_ratio_, accuracy\n",
    "\n",
    "# Example usage:\n",
    "# df is your DataFrame with 'feature' and 'Gesture_ID' columns\n",
    "print(\"standardized\")\n",
    "explained_variance_ratio, accuracy = run_pca_knn(with_disability, n_components=10, n_neighbors=5)\n",
    "print(\"PCA Explained Variance Ratio:\", explained_variance_ratio)\n",
    "print(\"KNN Classification Accuracy:\", accuracy)\n",
    "print(\"\")\n",
    "print(\"user-def\") #better at user-def than standardized\n",
    "explained_variance_ratio, accuracy = run_pca_knn(userdef, n_components=10, n_neighbors=5)\n",
    "print(\"PCA Explained Variance Ratio:\", explained_variance_ratio)\n",
    "print(\"KNN Classification Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1823eba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: [0.9, 0.96, 0.97, 0.93, 0.96]\n",
      "standardized 0.9440000000000002\n",
      "KNN Accuracy: [0.9516129032258065, 0.9483870967741935, 0.9516129032258065, 0.9483870967741935, 0.9516129032258065]\n",
      "userdef 0.9503225806451614\n"
     ]
    }
   ],
   "source": [
    "#baseline knn\n",
    "def run_knn_baseline_with_expert(expert_data, remaining_data, target_column, n_neighbors=5, k=5):\n",
    "    # Flatten the features from both datasets\n",
    "    X_expert = flatten_features(expert_data['feature'])\n",
    "    X_remaining = flatten_features(remaining_data['feature'])\n",
    "    \n",
    "    # Combine the feature sets and their corresponding targets\n",
    "    X_combined = np.vstack((X_expert, X_remaining))\n",
    "    y_expert = expert_data[target_column].values\n",
    "    y_remaining = remaining_data[target_column].values\n",
    "    y_combined = np.concatenate((y_expert, y_remaining))\n",
    "\n",
    "    \n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_combined):\n",
    "        X_train, X_test = X_combined[train_index], X_combined[test_index]\n",
    "        y_train, y_test = y_combined[train_index], y_combined[test_index]\n",
    "\n",
    "        # Run KNN on the combined dataset\n",
    "        knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    return accuracies\n",
    "expert_data, remaining_data = hold_out_expert(with_disability, 'Participant')\n",
    "baseline_accuracies = run_knn_baseline_with_expert(expert_data, remaining_data, 'Gesture_Encoded')\n",
    "print(f'KNN Accuracy: {baseline_accuracies}')\n",
    "print(\"standardized\", np.mean(baseline_accuracies))\n",
    "\n",
    "pers_expert_data, pers_remaining_data = hold_out_expert(userdef, 'Participant')\n",
    "baseline_accuracies = run_knn_baseline_with_expert(pers_expert_data, pers_remaining_data, 'Gesture_Encoded')\n",
    "print(f'KNN Accuracy: {baseline_accuracies}')\n",
    "print(\"userdef\", np.mean(baseline_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabf679a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60afdefd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6002eb11",
   "metadata": {},
   "source": [
    "## NOT USING BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf79514f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12,)\n",
      "(4,)\n",
      "(13,)\n",
      "(3,)\n",
      "(13,)\n",
      "(3,)\n",
      "(13,)\n",
      "(3,)\n",
      "(13,)\n",
      "(3,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['P104', 'P111', 'P114', 'P116', 'P119', 'P123', 'P126', 'P131', 'P132']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see the shapes of all pid and expert_data for fitting\n",
    "def k_fold_cross_validation(data, expert_data, participant_column, target_column, k=5, n_neighbors=5, n_components=2):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_index, test_index in kf.split(data[participant_column].unique()):\n",
    "        train_ids = data[participant_column].unique()[train_index]\n",
    "        test_ids = data[participant_column].unique()[test_index]\n",
    "        print(train_ids.shape)\n",
    "        print(test_ids.shape)\n",
    "\n",
    "        train_data = data[data[participant_column].isin(train_ids)]\n",
    "        test_data = data[data[participant_column].isin(test_ids)]\n",
    "        diff_shape = []\n",
    "\n",
    "        for pid in train_ids:\n",
    "            pid_data = train_data[train_data[participant_column] == pid]\n",
    "            if expert_data.shape != pid_data.shape:\n",
    "                diff_shape.append(pid)\n",
    "    return diff_shape\n",
    "k_fold_cross_validation(remaining_data, expert_data, 'Participant', 'Gesture_Encoded', k=5, n_neighbors=5, n_components=1)\n",
    "\n",
    "#shape problem with 'P104', 'P111', 'P114', 'P116', 'P119', 'P123', 'P126', 'P131', 'P132'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78f83348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.644"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cca_knn_accuracy) #accuracy for each k-fold.... really poor (maybe because n_components is 1??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4c307784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracies: [0.3433962264150943, 0.4666666666666667, 0.38, 0.255, 0.31]\n",
      "Average accuracy: 0.3510125786163522\n"
     ]
    }
   ],
   "source": [
    "#### don't use\n",
    "# Hold out one participant as the expert\n",
    "def hold_out_expert(data, participant_column):\n",
    "    participant_ids = data[participant_column].unique()\n",
    "    expert_user = np.random.choice(participant_ids)  # Randomly select one participant as expert\n",
    "    data_expert = data[data[participant_column] == expert_user]  # Expert data\n",
    "    data_remaining = data[data[participant_column] != expert_user]  # Remaining data\n",
    "    return data_expert, data_remaining\n",
    "\n",
    "def apply_cca_between_expert_and_others(expert_data, participant_data, target_column, n_components):\n",
    "    \"\"\"\n",
    "    Apply CCA between expert data and a participant's data.\n",
    "    \n",
    "    Parameters:\n",
    "        expert_data (DataFrame): Expert user data.\n",
    "        participant_data (DataFrame): Participant data.\n",
    "        target_column (str): Name of the target column.\n",
    "        n_components (int): Number of CCA components.\n",
    "    \n",
    "    Returns:\n",
    "        X_cca (array): CCA-transformed features for the participant data.\n",
    "        y (array): Target values for the participant data.\n",
    "    \"\"\"\n",
    "    # Extract features and target\n",
    "    X_expert = np.vstack(expert_data['feature'].apply(lambda x: np.ravel(x)).values)\n",
    "    X_participant = np.vstack(participant_data['feature'].apply(lambda x: np.ravel(x)).values)\n",
    "    y = participant_data[target_column].values\n",
    "\n",
    "    # Encode target labels for CCA\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y).reshape(-1, 1)\n",
    "\n",
    "    # Apply CCA\n",
    "    cca = CCA(n_components=n_components)\n",
    "    X_cca, _ = cca.fit_transform(X_participant, y_encoded)\n",
    "\n",
    "    return X_cca, y\n",
    "\n",
    "def run_knn(X_train, y_train, X_test, y_test, n_neighbors):\n",
    "    \"\"\"\n",
    "    Run KNN classification on the transformed data and return the accuracy.\n",
    "    \n",
    "    Parameters:\n",
    "        X_train (array): CCA-transformed training features.\n",
    "        y_train (array): Training labels.\n",
    "        X_test (array): CCA-transformed test features.\n",
    "        y_test (array): Test labels.\n",
    "        n_neighbors (int): Number of neighbors for KNN.\n",
    "    \n",
    "    Returns:\n",
    "        accuracy (float): Classification accuracy of KNN.\n",
    "    \"\"\"\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "def k_fold_cross_validation(data, expert_data, participant_column, target_column, k=5, n_neighbors=5, n_components=2):\n",
    "    \"\"\"\n",
    "    Perform k-fold cross-validation using CCA between expert user data and participants,\n",
    "    and KNN classification on the transformed data.\n",
    "    \n",
    "    Parameters:\n",
    "        data (DataFrame): Input DataFrame containing participants' data.\n",
    "        expert_data (DataFrame): Expert user data for CCA.\n",
    "        participant_column (str): Name of the participant column.\n",
    "        target_column (str): Name of the target column.\n",
    "        k (int): Number of folds for cross-validation.\n",
    "        n_neighbors (int): Number of neighbors for KNN.\n",
    "        n_components (int): Number of CCA components.\n",
    "    \n",
    "    Returns:\n",
    "        accuracies (list): List of accuracies for each fold.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    \n",
    "    # k-fold cross-validation\n",
    "    for train_index, test_index in kf.split(data[participant_column].unique()):\n",
    "        train_ids = data[participant_column].unique()[train_index]\n",
    "        test_ids = data[participant_column].unique()[test_index]\n",
    "        \n",
    "        train_data = data[data[participant_column].isin(train_ids)]\n",
    "        test_data = data[data[participant_column].isin(test_ids)]\n",
    "        \n",
    "        # Apply CCA between expert and training participants\n",
    "        X_train_cca = []\n",
    "        y_train = []\n",
    "        for pid in train_ids:\n",
    "            pid_data = train_data[train_data[participant_column] == pid]\n",
    "            X_pid_cca, y_pid = apply_cca_between_expert_and_others(expert_data, pid_data, target_column, n_components)\n",
    "            X_train_cca.append(X_pid_cca)\n",
    "            y_train.append(y_pid)\n",
    "        \n",
    "        # Combine CCA-transformed training data\n",
    "        X_train_cca = np.vstack(X_train_cca)\n",
    "        y_train = np.concatenate(y_train)\n",
    "        \n",
    "        # Apply CCA between expert and testing participants\n",
    "        X_test_cca = []\n",
    "        y_test = []\n",
    "        for pid in test_ids:\n",
    "            pid_data = test_data[test_data[participant_column] == pid]\n",
    "            X_pid_cca, y_pid = apply_cca_between_expert_and_others(expert_data, pid_data, target_column, n_components)\n",
    "            X_test_cca.append(X_pid_cca)\n",
    "            y_test.append(y_pid)\n",
    "        \n",
    "        # Combine CCA-transformed testing data\n",
    "        X_test_cca = np.vstack(X_test_cca)\n",
    "        y_test = np.concatenate(y_test)\n",
    "        \n",
    "        # Run KNN on CCA-transformed data\n",
    "        accuracy = run_knn(X_train_cca, y_train, X_test_cca, y_test, n_neighbors)\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    return accuracies\n",
    "expert_data, remaining_data = hold_out_expert(result, 'Participant')\n",
    "accuracies = k_fold_cross_validation(remaining_data, expert_data, 'Participant', 'Gesture_ID', k=5, n_neighbors=10, n_components=1)\n",
    "print(\"Cross-validation accuracies:\", accuracies)\n",
    "print(\"Average accuracy:\", np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f5d5247",
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution with resampling -- didn't use for final run through\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.utils import resample\n",
    "\n",
    "def apply_cca_between_expert_and_others(expert_data, other_data, target_column, n_components=2):\n",
    "    # Separate features (X) and target (y)\n",
    "    X_expert = flatten_features(expert_data['feature'])\n",
    "    X_other = flatten_features(other_data['feature'])\n",
    "\n",
    "    y_expert = expert_data[target_column]\n",
    "    y_other = other_data[target_column]\n",
    "    \n",
    "    # Match the sample size between X_expert and X_other\n",
    "    X_other_resampled, y_other_resampled = resample(X_other, y_other, n_samples=X_expert.shape[0], random_state=42)\n",
    "    \n",
    "    # Apply CCA between expert and other participant\n",
    "    cca = CCA(n_components=n_components)\n",
    "    cca.fit(X_expert, X_other_resampled)\n",
    "    X_other_cca = cca.transform(X_other_resampled)\n",
    "    \n",
    "    return X_other_cca, y_other_resampled#, X_expert, X_other_resampled\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a5d142",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to relabel freq_data to time data. and turn that to np.fft.fft to convert to time\n",
    "\n",
    "# Parseval's theorem verification function\n",
    "def parsevals_theorem_verification(df_freq):\n",
    "    time_domain_data = {}\n",
    "    freq_domain_squares_sum = {}\n",
    "    time_domain_squares_sum = {}\n",
    "\n",
    "    for sensor in df_freq.columns:\n",
    "        # Extract the time domain data for the sensor (column of the dataframe)\n",
    "        time_data = df_freq[sensor].values\n",
    "        \n",
    "        # FFT to transform to freq domain\n",
    "        freq_data = np.fft.fft(time_data)\n",
    "        \n",
    "        # Parseval's theorem: Sum of squares in the frequency domain\n",
    "        freq_domain_sum_sq = np.sum(np.abs(freq_data)**2)\n",
    "        \n",
    "        # Parseval's theorem: Sum of squares in the time domain\n",
    "        time_domain_sum_sq = np.sum(np.abs(time_data)**2)\n",
    "        \n",
    "        # Store results in dictionaries\n",
    "        time_domain_data[sensor] = time_data\n",
    "        freq_domain_squares_sum[sensor] = freq_domain_sum_sq\n",
    "        time_domain_squares_sum[sensor] = time_domain_sum_sq\n",
    "        \n",
    "        # Output verification for this sensor\n",
    "        print(f'Sensor: {sensor}')\n",
    "        print(f'Sum of squares (Frequency domain): {freq_domain_sum_sq}')\n",
    "        print(f'Sum of squares (Time domain): {time_domain_sum_sq}')\n",
    "        print(f'Parseval\\'s theorem holds: {np.isclose(freq_domain_sum_sq, time_domain_sum_sq)}\\n')\n",
    "    \n",
    "    return pd.DataFrame(time_domain_data), freq_domain_squares_sum, time_domain_squares_sum\n",
    "\n",
    "# Assuming df_freq is your dataframe with frequency domain EMG data\n",
    "# df_time, freq_squares, time_squares = parsevals_theorem_verification(df_freq)\n",
    "\n",
    "\n",
    "#want to see that freq_domain_sum_sq is the same as time_domain_sum_sq\n",
    "#can try and generalize by gesture trial as opposed to by column\n",
    "#load in metadata and break up huge dataframe by each gesture chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dbb42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsevals_theorem_verification(EMG_sliced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea8e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "###NOT USING\n",
    "#RAN INTO ISSUE WITH TAKING SECOND LOG OF NEG VALUES SINCE LOG(ZERO/DOT) GAVE NEG VALUES\n",
    "# either follow code in cell below to take maximum or maybe do abs value of log(zero/dot)?? these are both diff from original formula though\n",
    "def third_order_moment_log(df_freq, second_order_moments_raw, first_order_moments_raw, zero_order_moments_raw):\n",
    "    # Step 1: Compute the square roots\n",
    "    sqrt_first_diff = np.sqrt(zero_order_moments_raw - first_order_moments_raw)\n",
    "    sqrt_second_diff = np.sqrt(zero_order_moments_raw - second_order_moments_raw)\n",
    "    #print(sqrt_first_diff)\n",
    "    #print(sqrt_second_diff)\n",
    "    \n",
    "    # Step 2: Perform the dot product\n",
    "    dot_product = np.dot(sqrt_first_diff, sqrt_second_diff)\n",
    "    #print(dot_product)\n",
    "    # Step 3: Compute the sparseness formula\n",
    "    sparseness = np.log(np.abs(zero_order_moments_raw / dot_product))\n",
    "    print(zero_order_moments_raw)\n",
    "    print(dot_product)\n",
    "    \n",
    "    print(sparseness)\n",
    "    \n",
    "    # Step 4: Apply the logarithm again for third-order moments\n",
    "    third_order_moments_log = np.log(sparseness)\n",
    "    \n",
    "    return third_order_moments_log\n",
    "third_order_moments_log = third_order_moment_log(EMG_sliced, second_order_moments_raw, first_order_moments_raw, zero_order_moments_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc43cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "###NOT USING\n",
    "def freq_second_order_moment_log(df_freq, zero_order_moments_raw):\n",
    "    second_order_moments_log = []\n",
    "    second_order_moments_raw = []\n",
    "\n",
    "    for i, sensor in enumerate(df_freq.columns):\n",
    "        # Extract the frequency domain data for the sensor (column of the dataframe)\n",
    "        time_data = df_freq[sensor].values\n",
    "        freq_data = np.fft.fft(time_data)\n",
    "        \n",
    "        # Step 1: Take first derivative\n",
    "        first_deriv = np.gradient(freq_data)\n",
    "        \n",
    "        #Step 2: take second derivative\n",
    "        second_deriv = np.gradient(first_deriv)\n",
    "        \n",
    "        # Step 3: Square the signal (power) at each frequency of the first deriv\n",
    "        signal_squared = np.abs(second_deriv) ** 2\n",
    "        \n",
    "        # Step 4: Integrate (sum) the squared values to get the total power\n",
    "        total_power = np.sum(signal_squared)\n",
    "        \n",
    "        # Step 4: Take the logarithm of the total power\n",
    "        log_total_power = np.log(total_power/(zero_order_moments_raw[i]**4))\n",
    "        \n",
    "        # Store the result in the dictionary\n",
    "        second_order_moments_log.append(log_total_power)\n",
    "        second_order_moments_raw.append(total_power)\n",
    "\n",
    "    \n",
    "    return second_order_moments_log, second_order_moments_raw\n",
    "\n",
    "freq_second_order_moments_log, second_order_moments_raw = freq_first_order_moment_log(EMG_sliced, zero_order_moments_raw)\n",
    "#output = zero_order_moments_log is the zeroeth feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a09a6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "###NOT USING\n",
    "def freq_first_order_moment_log(df_freq, freq_zero_order_moments_raw):\n",
    "    # Initialize lists to store the results for each sensor\n",
    "    first_order_moments_log = []\n",
    "    first_order_moments_raw = []\n",
    "    \n",
    "    for i,sensor in enumerate(df_freq.columns):\n",
    "        # Extract the frequency domain data for the sensor (column of the dataframe)\n",
    "        time_data = df_freq[sensor].values\n",
    "        freq_data = np.fft.fft(time_data)\n",
    "        \n",
    "        # Step 1: Take first derivative\n",
    "        first_deriv = np.gradient(freq_data)\n",
    "        \n",
    "        # Step 2: Square the signal (power) at each frequency of the first deriv\n",
    "        signal_squared = np.abs(first_deriv) ** 2\n",
    "        \n",
    "        # Step 3: Integrate (sum) the squared values to get the total power\n",
    "        total_power = np.sum(signal_squared)\n",
    "        \n",
    "        # Step 4: Take the logarithm of the total power\n",
    "        log_total_power = np.log(total_power / (zero_order_moments_raw[i]**2))\n",
    "        \n",
    "        # Store the results in the lists\n",
    "        first_order_moments_log.append(log_total_power)\n",
    "        first_order_moments_raw.append(total_power)\n",
    "\n",
    "    # Convert lists to numpy arrays for consistency\n",
    "    first_order_moments_log = np.array(first_order_moments_log)\n",
    "    first_order_moments_raw = np.array(first_order_moments_raw)\n",
    "    \n",
    "    return first_order_moments_log, first_order_moments_raw\n",
    "\n",
    "# Example usage:\n",
    "freq_first_order_moments_log, freq_first_order_moments_raw = freq_first_order_moment_log(EMG_sliced, freq_zero_order_moments_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d145b3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###NOT USING\n",
    "def freq_zero_order_moment_log(df_freq):\n",
    "    zero_order_moments_log = []\n",
    "    zero_order_moments_raw = []\n",
    "\n",
    "    for sensor in df_freq.columns:\n",
    "        # Extract the frequency domain data for the sensor (column of the dataframe)\n",
    "        time_data = df_freq[sensor].values\n",
    "        freq_data = np.fft.fft(time_data)\n",
    "\n",
    "        \n",
    "        # Step 1: Square the signal (power) at each frequency\n",
    "        signal_squared = np.abs(freq_data) ** 2\n",
    "        \n",
    "        # Step 2: Integrate (sum) the squared values to get the total power\n",
    "        total_power = np.sum(signal_squared)\n",
    "        \n",
    "        # Step 3: Take the logarithm of the total power\n",
    "        log_total_power = np.log(total_power)\n",
    "        \n",
    "        # Store the result in the dictionary\n",
    "        zero_order_moments_log.append(log_total_power)\n",
    "        zero_order_moments_raw.append(total_power)\n",
    "        \n",
    "        #convert to np.array for consistency\n",
    "    \n",
    "    return zero_order_moments_log, zero_order_moments_raw\n",
    "\n",
    "freq_zero_order_moments_log, freq_zero_order_moments_raw = freq_zero_order_moment_log(EMG_sliced)\n",
    "#output = zero_order_moments_log is the zeroeth feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a920672",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to do fft: need to slice out EMG data and only use that\n",
    "EMG_sliced = EMG_stand.iloc[:,3:]\n",
    "EMG_sliced"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
